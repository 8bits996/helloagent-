# Task04 æ·±å…¥å­¦ä¹  - 9.6ç« èŠ‚ é«˜çº§ä¸Šä¸‹æ–‡å·¥ç¨‹

**å­¦ä¹ æ—¥æœŸ**: 2024-12-22  
**å­¦ä¹ è€…**: Franke Chen

---

## ğŸ“š ç¬¬9.6ç«  é«˜çº§ä¸Šä¸‹æ–‡å·¥ç¨‹æŠ€æœ¯

### æ¦‚è¿°

åŸºç¡€çš„ä¸Šä¸‹æ–‡ç®¡ç†å·²ç»æŒæ¡,ç°åœ¨æ·±å…¥å­¦ä¹ æ›´é«˜çº§çš„æŠ€æœ¯:

1. **å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢** - ç²¾ç¡®çš„è¯­ä¹‰åŒ¹é…
2. **é€’å½’æ€»ç»“æŠ€æœ¯** - å¤„ç†è¶…é•¿æ–‡æ¡£
3. **åŠ¨æ€Few-shotå­¦ä¹ ** - æ™ºèƒ½ç¤ºä¾‹é€‰æ‹©
4. **ä¸Šä¸‹æ–‡ç¼“å­˜ä¼˜åŒ–** - é™ä½APIæˆæœ¬
5. **æ··åˆæ£€ç´¢ç­–ç•¥** - BM25 + å‘é‡
6. **ä¸Šä¸‹æ–‡é‡æ’åº** - ä¼˜åŒ–ä¿¡æ¯é¡ºåº

---

## ğŸ¯ 1. å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢

### 1.1 ä¸ºä»€ä¹ˆéœ€è¦å‘é‡æ£€ç´¢?

**é—®é¢˜**:
- å…³é”®è¯åŒ¹é…å¤ªç²—ç³™
- æ— æ³•ç†è§£è¯­ä¹‰
- åŒä¹‰è¯æ— æ³•åŒ¹é…

**ç¤ºä¾‹**:
```python
query = "å¦‚ä½•å­¦ä¹ ç¼–ç¨‹?"

# å…³é”®è¯åŒ¹é…
keyword_match("å­¦ä¹ Pythonçš„æœ€ä½³æ–¹æ³•")  # âŒ æ²¡æœ‰"ç¼–ç¨‹"å…³é”®è¯
keyword_match("ç¼–ç¨‹å…¥é—¨æŒ‡å—")          # âœ… æœ‰"ç¼–ç¨‹"

# å‘é‡åŒ¹é…
vector_match("å­¦ä¹ Pythonçš„æœ€ä½³æ–¹æ³•")   # âœ… è¯­ä¹‰ç›¸ä¼¼
vector_match("ç¼–ç¨‹å…¥é—¨æŒ‡å—")           # âœ… è¯­ä¹‰ç›¸ä¼¼
vector_match("ä»Šå¤©å¤©æ°”å¾ˆå¥½")           # âŒ è¯­ä¹‰ä¸ç›¸å…³
```

### 1.2 å·¥ä½œåŸç†

```
æ–‡æœ¬ â†’ Embeddingæ¨¡å‹ â†’ å‘é‡ â†’ ç›¸ä¼¼åº¦è®¡ç®—
```

**æµç¨‹**:
1. **æ–‡æœ¬å‘é‡åŒ–**: ä½¿ç”¨Embeddingæ¨¡å‹å°†æ–‡æœ¬è½¬ä¸ºå‘é‡
2. **ç›¸ä¼¼åº¦è®¡ç®—**: è®¡ç®—æŸ¥è¯¢å‘é‡ä¸å€™é€‰å‘é‡çš„ç›¸ä¼¼åº¦
3. **æ’åºé€‰æ‹©**: é€‰æ‹©æœ€ç›¸ä¼¼çš„top-kæ¡

**å¸¸ç”¨æ¨¡å‹**:
- `sentence-transformers/all-MiniLM-L6-v2` (è½»é‡çº§,å¿«é€Ÿ)
- `sentence-transformers/all-mpnet-base-v2` (é«˜è´¨é‡)
- `OpenAI text-embedding-ada-002` (å•†ä¸š,æ•ˆæœå¥½)
- `BAAI/bge-large-zh-v1.5` (ä¸­æ–‡ä¼˜åŒ–)

### 1.3 ç›¸ä¼¼åº¦åº¦é‡

#### ä½™å¼¦ç›¸ä¼¼åº¦ (æœ€å¸¸ç”¨)

```python
import numpy as np

def cosine_similarity(vec1, vec2):
    """
    è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    
    å€¼èŒƒå›´: -1 åˆ° 1
    1: å®Œå…¨ç›¸åŒ
    0: æ­£äº¤(æ— å…³)
    -1: å®Œå…¨ç›¸å
    """
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    return dot_product / (norm1 * norm2)
```

#### æ¬§æ°è·ç¦»

```python
def euclidean_distance(vec1, vec2):
    """
    è®¡ç®—æ¬§æ°è·ç¦»
    
    å€¼èŒƒå›´: 0 åˆ° âˆ
    0: å®Œå…¨ç›¸åŒ
    å€¼è¶Šå¤§: è¶Šä¸ç›¸ä¼¼
    """
    return np.linalg.norm(vec1 - vec2)
```

#### ç‚¹ç§¯ç›¸ä¼¼åº¦

```python
def dot_product_similarity(vec1, vec2):
    """
    è®¡ç®—ç‚¹ç§¯ç›¸ä¼¼åº¦
    
    å½’ä¸€åŒ–å‘é‡çš„ç‚¹ç§¯ = ä½™å¼¦ç›¸ä¼¼åº¦
    """
    return np.dot(vec1, vec2)
```

### 1.4 å®è·µåº”ç”¨

**åœºæ™¯1: å¯¹è¯å†å²æ£€ç´¢**
```python
# ä»100æ¡å†å²å¯¹è¯ä¸­æ‰¾åˆ°ä¸å½“å‰æŸ¥è¯¢æœ€ç›¸å…³çš„5æ¡
query = "å¦‚ä½•ä¼˜åŒ–Pythonä»£ç æ€§èƒ½?"

# å‘é‡åŒ–æ‰€æœ‰å†å²
history_vectors = [embed(msg) for msg in history]
query_vector = embed(query)

# è®¡ç®—ç›¸ä¼¼åº¦
similarities = [
    cosine_similarity(query_vector, h_vec) 
    for h_vec in history_vectors
]

# é€‰æ‹©top-5
top_5_indices = np.argsort(similarities)[-5:]
relevant_history = [history[i] for i in top_5_indices]
```

**åœºæ™¯2: æ™ºèƒ½ç¤ºä¾‹é€‰æ‹©**
```python
# ä»ç¤ºä¾‹åº“ä¸­é€‰æ‹©ä¸å½“å‰ä»»åŠ¡æœ€ç›¸å…³çš„ç¤ºä¾‹
task = "å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•"

# ç¤ºä¾‹åº“
examples = [
    "å†’æ³¡æ’åºå®ç°",
    "å¿«é€Ÿæ’åºè¯¦è§£",
    "å½’å¹¶æ’åºç®—æ³•",
    "æ•°æ®ç»“æ„åŸºç¡€"
]

# é€‰æ‹©æœ€ç›¸å…³çš„2ä¸ªç¤ºä¾‹
relevant_examples = select_by_similarity(task, examples, top_k=2)
# è¿”å›: ["å¿«é€Ÿæ’åºè¯¦è§£", "å½’å¹¶æ’åºç®—æ³•"]
```

---

## ğŸ¯ 2. é€’å½’æ€»ç»“æŠ€æœ¯

### 2.1 é—®é¢˜èƒŒæ™¯

**æŒ‘æˆ˜**: å¦‚ä½•æ€»ç»“è¶…é•¿æ–‡æ¡£?

```
100é¡µæ–‡æ¡£ â†’ ç›´æ¥æ€»ç»“ â†’ âŒ è¶…å‡ºTokené™åˆ¶

è§£å†³æ–¹æ¡ˆ: é€’å½’æ€»ç»“
100é¡µ â†’ åˆ†10ç»„ â†’ æ¯ç»„æ€»ç»“ â†’ å¾—åˆ°10ä¸ªæ‘˜è¦ â†’ å†æ€»ç»“ â†’ æœ€ç»ˆæ‘˜è¦
```

### 2.2 é€’å½’æ€»ç»“ç®—æ³•

```python
def recursive_summarize(text, llm, max_chunk_size=2000):
    """
    é€’å½’æ€»ç»“é•¿æ–‡æœ¬
    
    Args:
        text: è¦æ€»ç»“çš„æ–‡æœ¬
        llm: LLMå®¢æˆ·ç«¯
        max_chunk_size: æ¯å—æœ€å¤§å­—ç¬¦æ•°
    
    Returns:
        æœ€ç»ˆæ€»ç»“
    """
    # åŸºç¡€æƒ…å†µ: æ–‡æœ¬è¶³å¤ŸçŸ­,ç›´æ¥æ€»ç»“
    if len(text) <= max_chunk_size:
        return llm.summarize(text)
    
    # é€’å½’æƒ…å†µ: åˆ†å—æ€»ç»“,å†æ€»ç»“æ‘˜è¦
    chunks = split_into_chunks(text, max_chunk_size)
    
    # æ€»ç»“æ¯ä¸€å—
    summaries = [llm.summarize(chunk) for chunk in chunks]
    
    # åˆå¹¶æ‰€æœ‰æ‘˜è¦
    combined = "\n".join(summaries)
    
    # é€’å½’æ€»ç»“æ‘˜è¦
    return recursive_summarize(combined, llm, max_chunk_size)
```

### 2.3 MapReduceæ€»ç»“

```python
def map_reduce_summarize(documents, llm):
    """
    MapReduceé£æ ¼çš„æ€»ç»“
    
    Mapé˜¶æ®µ: å¹¶è¡Œæ€»ç»“æ¯ä¸ªæ–‡æ¡£
    Reduceé˜¶æ®µ: åˆå¹¶æ‰€æœ‰æ‘˜è¦
    """
    # Map: å¹¶è¡Œæ€»ç»“
    summaries = parallel_map(llm.summarize, documents)
    
    # Reduce: åˆå¹¶æ‘˜è¦
    while len(summaries) > 1:
        # ä¸¤ä¸¤åˆå¹¶
        pairs = chunk_list(summaries, 2)
        summaries = [
            llm.summarize(f"{s1}\n{s2}") 
            for s1, s2 in pairs
        ]
    
    return summaries[0]
```

### 2.4 åˆ†å±‚æ€»ç»“

```
åŸæ–‡æ¡£ (100é¡µ)
  â†“
ç¬¬1å±‚æ€»ç»“ (æ¯10é¡µâ†’1é¡µ, å¾—åˆ°10é¡µ)
  â†“
ç¬¬2å±‚æ€»ç»“ (æ¯10é¡µâ†’1é¡µ, å¾—åˆ°1é¡µ)
  â†“
æœ€ç»ˆæ‘˜è¦ (1é¡µ)
```

**ä¼˜ç‚¹**:
- ä¿ç•™å±‚æ¬¡ç»“æ„
- å¯ä»¥æŸ¥çœ‹ä¸­é—´ç»“æœ
- æ›´å¥½çš„ä¿¡æ¯ä¿ç•™

---

## ğŸ¯ 3. åŠ¨æ€Few-shotç¤ºä¾‹é€‰æ‹©

### 3.1 ä»€ä¹ˆæ˜¯Few-shotå­¦ä¹ ?

**å®šä¹‰**: é€šè¿‡æä¾›å°‘é‡ç¤ºä¾‹æ¥å¼•å¯¼LLMå®Œæˆä»»åŠ¡

**ä¼ ç»Ÿæ–¹å¼** (é™æ€ç¤ºä¾‹):
```python
prompt = """
è¯·å°†ä»¥ä¸‹å¥å­ç¿»è¯‘æˆè‹±æ–‡:

ç¤ºä¾‹1:
ä¸­æ–‡: ä½ å¥½
è‹±æ–‡: Hello

ç¤ºä¾‹2:
ä¸­æ–‡: è°¢è°¢
è‹±æ–‡: Thank you

ç°åœ¨ç¿»è¯‘:
ä¸­æ–‡: æ—©ä¸Šå¥½
è‹±æ–‡:
"""
```

**é—®é¢˜**:
- ç¤ºä¾‹æ˜¯å›ºå®šçš„
- å¯èƒ½ä¸å½“å‰ä»»åŠ¡ä¸ç›¸å…³
- æµªè´¹Token

### 3.2 åŠ¨æ€ç¤ºä¾‹é€‰æ‹©

**åŸç†**: æ ¹æ®å½“å‰ä»»åŠ¡,ä»ç¤ºä¾‹åº“ä¸­é€‰æ‹©æœ€ç›¸å…³çš„ç¤ºä¾‹

```python
class DynamicFewShotSelector:
    """åŠ¨æ€Few-shotç¤ºä¾‹é€‰æ‹©å™¨"""
    
    def __init__(self, example_pool, embedding_model):
        """
        Args:
            example_pool: ç¤ºä¾‹æ± 
            embedding_model: Embeddingæ¨¡å‹
        """
        self.examples = example_pool
        
        # é¢„å…ˆè®¡ç®—æ‰€æœ‰ç¤ºä¾‹çš„å‘é‡
        self.example_vectors = [
            embedding_model.encode(ex['input'])
            for ex in example_pool
        ]
        
        self.embedding_model = embedding_model
    
    def select_examples(self, query, k=3):
        """
        é€‰æ‹©æœ€ç›¸å…³çš„kä¸ªç¤ºä¾‹
        
        Args:
            query: å½“å‰æŸ¥è¯¢
            k: é€‰æ‹©æ•°é‡
        
        Returns:
            æœ€ç›¸å…³çš„kä¸ªç¤ºä¾‹
        """
        # è®¡ç®—æŸ¥è¯¢å‘é‡
        query_vector = self.embedding_model.encode(query)
        
        # è®¡ç®—ä¸æ‰€æœ‰ç¤ºä¾‹çš„ç›¸ä¼¼åº¦
        similarities = [
            cosine_similarity(query_vector, ex_vec)
            for ex_vec in self.example_vectors
        ]
        
        # é€‰æ‹©top-k
        top_k_indices = np.argsort(similarities)[-k:]
        
        return [self.examples[i] for i in top_k_indices]
```

### 3.3 ä½¿ç”¨ç¤ºä¾‹

```python
# å‡†å¤‡ç¤ºä¾‹æ± 
example_pool = [
    {
        "input": "å¦‚ä½•æ’åºåˆ—è¡¨?",
        "output": "ä½¿ç”¨list.sort()æˆ–sorted()å‡½æ•°"
    },
    {
        "input": "å¦‚ä½•è¯»å–æ–‡ä»¶?",
        "output": "ä½¿ç”¨open()å‡½æ•°é…åˆwithè¯­å¥"
    },
    {
        "input": "å¦‚ä½•å¤„ç†å¼‚å¸¸?",
        "output": "ä½¿ç”¨try-exceptå—"
    },
    # ... æ›´å¤šç¤ºä¾‹
]

# åˆ›å»ºé€‰æ‹©å™¨
selector = DynamicFewShotSelector(example_pool, embedding_model)

# å½“å‰ä»»åŠ¡
query = "å¦‚ä½•å†™å…¥æ–‡ä»¶?"

# é€‰æ‹©æœ€ç›¸å…³çš„2ä¸ªç¤ºä¾‹
relevant_examples = selector.select_examples(query, k=2)
# å¯èƒ½è¿”å›: ["å¦‚ä½•è¯»å–æ–‡ä»¶?", "å¦‚ä½•å¤„ç†å¼‚å¸¸?"]

# æ„å»ºPrompt
prompt = build_prompt_with_examples(query, relevant_examples)
```

### 3.4 å¤šæ ·æ€§é€‰æ‹©

**é—®é¢˜**: åªæŒ‰ç›¸ä¼¼åº¦é€‰æ‹©å¯èƒ½å¯¼è‡´ç¤ºä¾‹è¿‡äºç›¸ä¼¼

**è§£å†³**: MMR (Maximal Marginal Relevance)

```python
def select_diverse_examples(query, examples, k=3, lambda_param=0.5):
    """
    é€‰æ‹©æ—¢ç›¸å…³åˆå¤šæ ·çš„ç¤ºä¾‹
    
    Args:
        query: æŸ¥è¯¢
        examples: å€™é€‰ç¤ºä¾‹
        k: é€‰æ‹©æ•°é‡
        lambda_param: ç›¸å…³æ€§vså¤šæ ·æ€§æƒé‡ (0-1)
    
    Returns:
        é€‰æ‹©çš„ç¤ºä¾‹
    """
    query_vec = embed(query)
    example_vecs = [embed(ex) for ex in examples]
    
    selected = []
    selected_vecs = []
    
    for _ in range(k):
        best_score = -float('inf')
        best_idx = None
        
        for i, (ex, ex_vec) in enumerate(zip(examples, example_vecs)):
            if ex in selected:
                continue
            
            # ç›¸å…³æ€§åˆ†æ•°
            relevance = cosine_similarity(query_vec, ex_vec)
            
            # å¤šæ ·æ€§åˆ†æ•° (ä¸å·²é€‰ç¤ºä¾‹çš„æœ€å¤§ç›¸ä¼¼åº¦)
            if selected_vecs:
                max_sim = max(
                    cosine_similarity(ex_vec, s_vec)
                    for s_vec in selected_vecs
                )
                diversity = 1 - max_sim
            else:
                diversity = 1.0
            
            # MMRåˆ†æ•°
            score = lambda_param * relevance + (1 - lambda_param) * diversity
            
            if score > best_score:
                best_score = score
                best_idx = i
        
        selected.append(examples[best_idx])
        selected_vecs.append(example_vecs[best_idx])
    
    return selected
```

---

## ğŸ¯ 4. ä¸Šä¸‹æ–‡ç¼“å­˜ä¼˜åŒ–

### 4.1 é—®é¢˜èƒŒæ™¯

**æˆæœ¬é—®é¢˜**:
```python
# æ¯æ¬¡è¯·æ±‚éƒ½å‘é€å®Œæ•´ä¸Šä¸‹æ–‡
request_1: system_prompt (500 tokens) + history (1000 tokens)
request_2: system_prompt (500 tokens) + history (1200 tokens)
request_3: system_prompt (500 tokens) + history (1500 tokens)

# system_prompté‡å¤å‘é€,æµªè´¹æˆæœ¬!
```

### 4.2 ç¼“å­˜ç­–ç•¥

#### ç­–ç•¥1: ç³»ç»Ÿæç¤ºè¯ç¼“å­˜

```python
class CachedContextManager:
    """å¸¦ç¼“å­˜çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    
    def __init__(self):
        self.system_prompt_cache = None
        self.system_prompt = None
    
    def set_system_prompt(self, prompt):
        """è®¾ç½®ç³»ç»Ÿæç¤ºè¯"""
        if prompt != self.system_prompt:
            self.system_prompt = prompt
            # è°ƒç”¨APIç¼“å­˜ç³»ç»Ÿæç¤ºè¯
            self.system_prompt_cache = cache_prompt(prompt)
    
    def get_context(self):
        """è·å–ä¸Šä¸‹æ–‡,ä½¿ç”¨ç¼“å­˜çš„ç³»ç»Ÿæç¤ºè¯"""
        return {
            "system_cache_id": self.system_prompt_cache,  # ä½¿ç”¨ç¼“å­˜
            "messages": self.history
        }
```

#### ç­–ç•¥2: å‰ç¼€ç¼“å­˜

**åŸç†**: å¯¹è¯çš„å‰åŠéƒ¨åˆ†é€šå¸¸ä¸å˜,å¯ä»¥ç¼“å­˜

```python
# è¯·æ±‚1
context_1 = [msg1, msg2, msg3, msg4, msg5]
# ç¼“å­˜å‰3æ¡: cache_id = "abc123"

# è¯·æ±‚2 (åªéœ€å‘é€æ–°æ¶ˆæ¯)
context_2 = {
    "cache_prefix": "abc123",  # å¤ç”¨ç¼“å­˜
    "new_messages": [msg6, msg7]
}
```

**èŠ‚çœ**:
- å‡å°‘å‘é€çš„Tokenæ•°
- é™ä½APIæˆæœ¬
- æé«˜å“åº”é€Ÿåº¦

### 4.3 ç¼“å­˜å¤±æ•ˆç­–ç•¥

```python
class SmartCache:
    """æ™ºèƒ½ç¼“å­˜ç®¡ç†"""
    
    def __init__(self, ttl=3600):
        """
        Args:
            ttl: Time To Live (ç§’)
        """
        self.cache = {}
        self.ttl = ttl
    
    def get(self, key):
        """è·å–ç¼“å­˜"""
        if key in self.cache:
            item = self.cache[key]
            
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if time.time() - item['timestamp'] < self.ttl:
                return item['value']
            else:
                # è¿‡æœŸ,åˆ é™¤
                del self.cache[key]
        
        return None
    
    def set(self, key, value):
        """è®¾ç½®ç¼“å­˜"""
        self.cache[key] = {
            'value': value,
            'timestamp': time.time()
        }
    
    def invalidate(self, pattern):
        """å¤±æ•ˆåŒ¹é…æ¨¡å¼çš„ç¼“å­˜"""
        keys_to_delete = [
            key for key in self.cache
            if pattern in key
        ]
        for key in keys_to_delete:
            del self.cache[key]
```

### 4.4 å¤šçº§ç¼“å­˜

```
L1ç¼“å­˜ (å†…å­˜) - æå¿«,å°å®¹é‡
   â†“ miss
L2ç¼“å­˜ (Redis) - å¿«,ä¸­å®¹é‡
   â†“ miss
L3ç¼“å­˜ (æ•°æ®åº“) - æ…¢,å¤§å®¹é‡
   â†“ miss
é‡æ–°ç”Ÿæˆ
```

---

## ğŸ¯ 5. æ··åˆæ£€ç´¢ç­–ç•¥ (BM25 + å‘é‡)

### 5.1 ä¸ºä»€ä¹ˆéœ€è¦æ··åˆæ£€ç´¢?

**å‘é‡æ£€ç´¢çš„å±€é™**:
- è¯­ä¹‰ç›¸ä¼¼ä½†å…³é”®è¯ä¸åŒ¹é…: âŒ
- ä¸“æœ‰åè¯åŒ¹é…: âŒ

**BM25çš„ä¼˜åŠ¿**:
- ç²¾ç¡®å…³é”®è¯åŒ¹é…: âœ…
- ä¸“æœ‰åè¯: âœ…
- ä¸éœ€è¦è®­ç»ƒ: âœ…

**æ··åˆæ£€ç´¢**: ç»“åˆä¸¤è€…ä¼˜åŠ¿

### 5.2 BM25ç®—æ³•

```python
from rank_bm25 import BM25Okapi
import jieba  # ä¸­æ–‡åˆ†è¯

class BM25Retriever:
    """BM25æ£€ç´¢å™¨"""
    
    def __init__(self, documents):
        """
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
        """
        # åˆ†è¯
        tokenized_docs = [
            list(jieba.cut(doc))
            for doc in documents
        ]
        
        # åˆ›å»ºBM25ç´¢å¼•
        self.bm25 = BM25Okapi(tokenized_docs)
        self.documents = documents
    
    def search(self, query, top_k=5):
        """
        æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢
            top_k: è¿”å›æ•°é‡
        
        Returns:
            ç›¸å…³æ–‡æ¡£åŠåˆ†æ•°
        """
        # åˆ†è¯
        tokenized_query = list(jieba.cut(query))
        
        # BM25è¯„åˆ†
        scores = self.bm25.get_scores(tokenized_query)
        
        # æ’åº
        top_indices = np.argsort(scores)[-top_k:][::-1]
        
        return [
            {
                'document': self.documents[i],
                'score': scores[i]
            }
            for i in top_indices
        ]
```

### 5.3 æ··åˆæ£€ç´¢å®ç°

```python
class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨: BM25 + å‘é‡"""
    
    def __init__(self, documents, embedding_model):
        self.bm25 = BM25Retriever(documents)
        self.vector = VectorRetriever(documents, embedding_model)
        self.documents = documents
    
    def search(self, query, top_k=5, alpha=0.5):
        """
        æ··åˆæ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢
            top_k: è¿”å›æ•°é‡
            alpha: BM25æƒé‡ (0-1), å‘é‡æƒé‡ä¸º1-alpha
        
        Returns:
            æ£€ç´¢ç»“æœ
        """
        # BM25æ£€ç´¢
        bm25_results = self.bm25.search(query, top_k=top_k*2)
        
        # å‘é‡æ£€ç´¢
        vector_results = self.vector.search(query, top_k=top_k*2)
        
        # å½’ä¸€åŒ–åˆ†æ•°
        bm25_scores = self._normalize_scores(
            [r['score'] for r in bm25_results]
        )
        vector_scores = self._normalize_scores(
            [r['score'] for r in vector_results]
        )
        
        # åˆå¹¶åˆ†æ•°
        combined_scores = {}
        
        for i, result in enumerate(bm25_results):
            doc = result['document']
            combined_scores[doc] = alpha * bm25_scores[i]
        
        for i, result in enumerate(vector_results):
            doc = result['document']
            if doc in combined_scores:
                combined_scores[doc] += (1-alpha) * vector_scores[i]
            else:
                combined_scores[doc] = (1-alpha) * vector_scores[i]
        
        # æ’åº
        sorted_docs = sorted(
            combined_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        return [doc for doc, score in sorted_docs[:top_k]]
    
    def _normalize_scores(self, scores):
        """å½’ä¸€åŒ–åˆ†æ•°åˆ°0-1"""
        if not scores:
            return []
        
        min_score = min(scores)
        max_score = max(scores)
        
        if max_score == min_score:
            return [1.0] * len(scores)
        
        return [
            (score - min_score) / (max_score - min_score)
            for score in scores
        ]
```

### 5.4 è‡ªé€‚åº”æƒé‡

```python
def adaptive_hybrid_search(query, documents):
    """
    è‡ªé€‚åº”æ··åˆæ£€ç´¢
    
    æ ¹æ®æŸ¥è¯¢ç‰¹ç‚¹åŠ¨æ€è°ƒæ•´BM25å’Œå‘é‡çš„æƒé‡
    """
    # åˆ†ææŸ¥è¯¢ç‰¹ç‚¹
    has_keywords = contains_specific_terms(query)
    is_semantic = is_semantic_query(query)
    
    # åŠ¨æ€è°ƒæ•´æƒé‡
    if has_keywords and not is_semantic:
        alpha = 0.8  # åé‡BM25
    elif is_semantic and not has_keywords:
        alpha = 0.2  # åé‡å‘é‡
    else:
        alpha = 0.5  # å‡è¡¡
    
    return hybrid_search(query, documents, alpha=alpha)
```

---

## ğŸ¯ 6. ä¸Šä¸‹æ–‡é‡æ’åº (Reranking)

### 6.1 ä¸ºä»€ä¹ˆéœ€è¦é‡æ’åº?

**é—®é¢˜**: åˆå§‹æ£€ç´¢å¯èƒ½ä¸å¤Ÿç²¾ç¡®

```
æ£€ç´¢é˜¶æ®µ: å¿«é€Ÿ,å¬å›ç‡é«˜,ä½†å¯èƒ½ä¸ç²¾ç¡®
  â†“ è¿”å›top-100
é‡æ’åºé˜¶æ®µ: æ…¢,ä½†æ›´ç²¾ç¡®
  â†“ è¿”å›top-10
æœ€ç»ˆç»“æœ: ç²¾ç¡®ä¸”ç›¸å…³
```

### 6.2 åŸºäºLLMçš„é‡æ’åº

```python
class LLMReranker:
    """ä½¿ç”¨LLMé‡æ’åº"""
    
    def __init__(self, llm):
        self.llm = llm
    
    def rerank(self, query, candidates, top_k=5):
        """
        é‡æ’åºå€™é€‰æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢
            candidates: å€™é€‰æ–‡æ¡£åˆ—è¡¨
            top_k: è¿”å›æ•°é‡
        
        Returns:
            é‡æ’åºåçš„æ–‡æ¡£
        """
        scored = []
        
        for doc in candidates:
            # è®©LLMè¯„åˆ†ç›¸å…³æ€§
            score = self._score_relevance(query, doc)
            scored.append((doc, score))
        
        # æŒ‰åˆ†æ•°æ’åº
        scored.sort(key=lambda x: x[1], reverse=True)
        
        return [doc for doc, score in scored[:top_k]]
    
    def _score_relevance(self, query, document):
        """
        LLMè¯„åˆ†æ–‡æ¡£ç›¸å…³æ€§
        
        Returns:
            ç›¸å…³æ€§åˆ†æ•° (0-10)
        """
        prompt = f"""
è¯·è¯„ä¼°ä»¥ä¸‹æ–‡æ¡£ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§,æ‰“åˆ†0-10:

æŸ¥è¯¢: {query}

æ–‡æ¡£: {document}

ç›¸å…³æ€§åˆ†æ•°(åªè¿”å›æ•°å­—):"""
        
        response = self.llm.chat(prompt)
        
        try:
            score = float(response.strip())
            return max(0, min(10, score))  # é™åˆ¶åœ¨0-10
        except:
            return 5.0  # é»˜è®¤ä¸­ç­‰ç›¸å…³
```

### 6.3 äº¤å‰ç¼–ç å™¨é‡æ’åº

```python
from sentence_transformers import CrossEncoder

class CrossEncoderReranker:
    """äº¤å‰ç¼–ç å™¨é‡æ’åº"""
    
    def __init__(self, model_name='cross-encoder/ms-marco-MiniLM-L-6-v2'):
        self.model = CrossEncoder(model_name)
    
    def rerank(self, query, candidates, top_k=5):
        """
        é‡æ’åº
        
        äº¤å‰ç¼–ç å™¨ä¼šåŒæ—¶ç¼–ç queryå’Œdocument,
        æ¯”åˆ†åˆ«ç¼–ç æ›´ç²¾ç¡®
        """
        # å‡†å¤‡è¾“å…¥å¯¹
        pairs = [[query, doc] for doc in candidates]
        
        # é¢„æµ‹åˆ†æ•°
        scores = self.model.predict(pairs)
        
        # æ’åº
        scored = list(zip(candidates, scores))
        scored.sort(key=lambda x: x[1], reverse=True)
        
        return [doc for doc, score in scored[:top_k]]
```

### 6.4 ä¸¤é˜¶æ®µæ£€ç´¢

```python
def two_stage_retrieval(query, documents, k1=100, k2=10):
    """
    ä¸¤é˜¶æ®µæ£€ç´¢
    
    é˜¶æ®µ1: å¿«é€Ÿæ£€ç´¢,å¬å›top-100
    é˜¶æ®µ2: ç²¾ç¡®é‡æ’åº,è¿”å›top-10
    
    Args:
        query: æŸ¥è¯¢
        documents: æ‰€æœ‰æ–‡æ¡£
        k1: ç¬¬ä¸€é˜¶æ®µå¬å›æ•°é‡
        k2: æœ€ç»ˆè¿”å›æ•°é‡
    
    Returns:
        æœ€ç›¸å…³çš„k2ä¸ªæ–‡æ¡£
    """
    # é˜¶æ®µ1: å¿«é€Ÿå‘é‡æ£€ç´¢
    stage1_results = vector_search(query, documents, top_k=k1)
    
    # é˜¶æ®µ2: äº¤å‰ç¼–ç å™¨é‡æ’åº
    reranker = CrossEncoderReranker()
    final_results = reranker.rerank(query, stage1_results, top_k=k2)
    
    return final_results
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### æ£€ç´¢ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥ | å¬å›ç‡ | ç²¾ç¡®åº¦ | é€Ÿåº¦ | æˆæœ¬ |
|------|--------|--------|------|------|
| å…³é”®è¯ | 60% | 70% | âš¡âš¡âš¡ | ğŸ’° |
| BM25 | 70% | 75% | âš¡âš¡âš¡ | ğŸ’° |
| å‘é‡ | 85% | 80% | âš¡âš¡ | ğŸ’°ğŸ’° |
| æ··åˆ | 90% | 85% | âš¡âš¡ | ğŸ’°ğŸ’° |
| æ··åˆ+é‡æ’åº | 90% | 95% | âš¡ | ğŸ’°ğŸ’°ğŸ’° |

### å‹ç¼©æŠ€æœ¯å¯¹æ¯”

| æŠ€æœ¯ | å‹ç¼©ç‡ | ä¿¡æ¯ä¿ç•™ | é€Ÿåº¦ | æˆæœ¬ |
|------|--------|----------|------|------|
| æˆªæ–­ | 30% | â­â­â­ | âš¡âš¡âš¡ | ğŸ’° |
| æ€»ç»“ | 70% | â­â­â­â­ | âš¡ | ğŸ’°ğŸ’°ğŸ’° |
| é€’å½’æ€»ç»“ | 90% | â­â­â­â­â­ | âš¡ | ğŸ’°ğŸ’°ğŸ’°ğŸ’° |

---

## ğŸ’¡ æœ€ä½³å®è·µå»ºè®®

### 1. é€‰æ‹©åˆé€‚çš„æŠ€æœ¯æ ˆ

**å°è§„æ¨¡åº”ç”¨** (< 1000æ–‡æ¡£):
- ç®€å•å‘é‡æ£€ç´¢
- åŸºç¡€å‹ç¼©
- ä¸éœ€è¦ç¼“å­˜

**ä¸­è§„æ¨¡åº”ç”¨** (1000-10000æ–‡æ¡£):
- æ··åˆæ£€ç´¢
- é€’å½’æ€»ç»“
- Redisç¼“å­˜

**å¤§è§„æ¨¡åº”ç”¨** (> 10000æ–‡æ¡£):
- æ··åˆæ£€ç´¢ + é‡æ’åº
- åˆ†å¸ƒå¼ç¼“å­˜
- ä¸“ç”¨å‘é‡æ•°æ®åº“

### 2. æˆæœ¬ä¼˜åŒ–

```python
# ä¼˜å…ˆçº§æ’åº
priorities = [
    "1. ä½¿ç”¨ç¼“å­˜ (èŠ‚çœ40-60%)",
    "2. ä¸Šä¸‹æ–‡å‹ç¼© (èŠ‚çœ30-50%)",
    "3. æ‰¹å¤„ç†è¯·æ±‚ (èŠ‚çœ20-30%)",
    "4. é€‰æ‹©åˆé€‚æ¨¡å‹ (èŠ‚çœ10-20%)"
]
```

### 3. è´¨é‡ä¿è¯

```python
# ç›‘æ§æŒ‡æ ‡
metrics = {
    "å¬å›ç‡": "æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£ / æ‰€æœ‰ç›¸å…³æ–‡æ¡£",
    "ç²¾ç¡®åº¦": "æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£ / æ£€ç´¢åˆ°çš„æ‰€æœ‰æ–‡æ¡£",
    "MRR": "Mean Reciprocal Rank",
    "NDCG": "Normalized Discounted Cumulative Gain"
}
```

---

## ğŸš€ ä¸‹ä¸€æ­¥å®è·µ

åœ¨ä¸‹ä¸€éƒ¨åˆ†,æˆ‘ä»¬å°†å®ç°è¿™äº›é«˜çº§æŠ€æœ¯çš„å®Œæ•´ä»£ç :

1. âœ… å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢å™¨
2. âœ… é€’å½’æ€»ç»“å¼•æ“
3. âœ… åŠ¨æ€Few-shoté€‰æ‹©å™¨
4. âœ… æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ
5. âœ… æ··åˆæ£€ç´¢å¼•æ“
6. âœ… é‡æ’åºä¼˜åŒ–å™¨

---

**å­¦ä¹ æ—¶é—´**: [è¿›è¡Œä¸­]  
**å®Œæˆåº¦**: ç†è®ºå­¦ä¹  100%  
**ä¸‹ä¸€æ­¥**: å¼€å§‹é«˜çº§ä»£ç å®è·µ
