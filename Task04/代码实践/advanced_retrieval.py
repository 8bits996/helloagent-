"""
é«˜çº§æ£€ç´¢æŠ€æœ¯ (Advanced Retrieval)

å®ç°é«˜çº§ä¸Šä¸‹æ–‡æ£€ç´¢åŠŸèƒ½:
1. å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
2. BM25å…³é”®è¯æ£€ç´¢
3. æ··åˆæ£€ç´¢ç­–ç•¥
4. é‡æ’åºä¼˜åŒ–

æ³¨æ„: éœ€è¦å®‰è£…ä¾èµ–
pip install sentence-transformers rank-bm25 jieba numpy

Author: Franke Chen
Date: 2024-12-22
"""

from typing import List, Dict, Any, Tuple, Optional
from dataclasses import dataclass
import numpy as np
import time

# å°è¯•å¯¼å…¥å¯é€‰ä¾èµ–
try:
    from sentence_transformers import SentenceTransformer
    HAS_SENTENCE_TRANSFORMERS = True
except ImportError:
    HAS_SENTENCE_TRANSFORMERS = False
    print("âš ï¸  sentence-transformersæœªå®‰è£…,å‘é‡æ£€ç´¢åŠŸèƒ½å°†è¢«ç¦ç”¨")
    print("   å®‰è£…å‘½ä»¤: pip install sentence-transformers")

try:
    from rank_bm25 import BM25Okapi
    import jieba
    HAS_BM25 = True
except ImportError:
    HAS_BM25 = False
    print("âš ï¸  rank-bm25æˆ–jiebaæœªå®‰è£…,BM25æ£€ç´¢åŠŸèƒ½å°†è¢«ç¦ç”¨")
    print("   å®‰è£…å‘½ä»¤: pip install rank-bm25 jieba")


@dataclass
class SearchResult:
    """æ£€ç´¢ç»“æœ"""
    document: str
    score: float
    method: str  # 'vector', 'bm25', 'hybrid'
    metadata: Dict[str, Any] = None
    
    def __repr__(self) -> str:
        return f"SearchResult(score={self.score:.3f}, method={self.method}, doc={self.document[:50]}...)"


def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:
    """
    è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    
    Args:
        vec1: å‘é‡1
        vec2: å‘é‡2
    
    Returns:
        ç›¸ä¼¼åº¦ (-1åˆ°1)
    """
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    
    if norm1 == 0 or norm2 == 0:
        return 0.0
    
    return dot_product / (norm1 * norm2)


class VectorRetriever:
    """
    å‘é‡æ£€ç´¢å™¨
    
    ä½¿ç”¨Sentence-BERTè¿›è¡Œè¯­ä¹‰æ£€ç´¢
    """
    
    def __init__(
        self,
        documents: List[str],
        model_name: str = 'all-MiniLM-L6-v2'
    ):
        """
        åˆå§‹åŒ–
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            model_name: Embeddingæ¨¡å‹åç§°
        """
        if not HAS_SENTENCE_TRANSFORMERS:
            raise ImportError("éœ€è¦å®‰è£…sentence-transformers")
        
        self.documents = documents
        self.model = SentenceTransformer(model_name)
        
        # é¢„å…ˆè®¡ç®—æ‰€æœ‰æ–‡æ¡£çš„å‘é‡
        print(f"æ­£åœ¨ä¸º{len(documents)}ä¸ªæ–‡æ¡£ç”Ÿæˆå‘é‡...")
        self.doc_vectors = self.model.encode(
            documents,
            show_progress_bar=True,
            convert_to_numpy=True
        )
        print("âœ… å‘é‡ç”Ÿæˆå®Œæˆ!")
    
    def search(
        self,
        query: str,
        top_k: int = 5,
        min_score: float = 0.0
    ) -> List[SearchResult]:
        """
        å‘é‡æ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›æ•°é‡
            min_score: æœ€ä½ç›¸ä¼¼åº¦åˆ†æ•°
        
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        # æŸ¥è¯¢å‘é‡åŒ–
        query_vector = self.model.encode([query], convert_to_numpy=True)[0]
        
        # è®¡ç®—ä¸æ‰€æœ‰æ–‡æ¡£çš„ç›¸ä¼¼åº¦
        similarities = []
        for i, doc_vec in enumerate(self.doc_vectors):
            sim = cosine_similarity(query_vector, doc_vec)
            if sim >= min_score:
                similarities.append((i, sim))
        
        # æ’åº
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        # æ„å»ºç»“æœ
        results = []
        for idx, score in similarities[:top_k]:
            results.append(SearchResult(
                document=self.documents[idx],
                score=float(score),
                method='vector'
            ))
        
        return results


class BM25Retriever:
    """
    BM25æ£€ç´¢å™¨
    
    åŸºäºå…³é”®è¯çš„æ£€ç´¢,æ“…é•¿ç²¾ç¡®åŒ¹é…
    """
    
    def __init__(self, documents: List[str], language: str = 'zh'):
        """
        åˆå§‹åŒ–
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            language: è¯­è¨€ ('zh'ä¸­æ–‡, 'en'è‹±æ–‡)
        """
        if not HAS_BM25:
            raise ImportError("éœ€è¦å®‰è£…rank-bm25å’Œjieba")
        
        self.documents = documents
        self.language = language
        
        # åˆ†è¯
        print(f"æ­£åœ¨ä¸º{len(documents)}ä¸ªæ–‡æ¡£åˆ†è¯...")
        if language == 'zh':
            self.tokenized_docs = [
                list(jieba.cut(doc))
                for doc in documents
            ]
        else:
            self.tokenized_docs = [
                doc.lower().split()
                for doc in documents
            ]
        
        # åˆ›å»ºBM25ç´¢å¼•
        self.bm25 = BM25Okapi(self.tokenized_docs)
        print("âœ… BM25ç´¢å¼•åˆ›å»ºå®Œæˆ!")
    
    def search(
        self,
        query: str,
        top_k: int = 5,
        min_score: float = 0.0
    ) -> List[SearchResult]:
        """
        BM25æ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›æ•°é‡
            min_score: æœ€ä½åˆ†æ•°
        
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        # åˆ†è¯
        if self.language == 'zh':
            tokenized_query = list(jieba.cut(query))
        else:
            tokenized_query = query.lower().split()
        
        # BM25è¯„åˆ†
        scores = self.bm25.get_scores(tokenized_query)
        
        # ç­›é€‰å’Œæ’åº
        scored_docs = [
            (i, score)
            for i, score in enumerate(scores)
            if score >= min_score
        ]
        scored_docs.sort(key=lambda x: x[1], reverse=True)
        
        # æ„å»ºç»“æœ
        results = []
        for idx, score in scored_docs[:top_k]:
            results.append(SearchResult(
                document=self.documents[idx],
                score=float(score),
                method='bm25'
            ))
        
        return results


class HybridRetriever:
    """
    æ··åˆæ£€ç´¢å™¨
    
    ç»“åˆå‘é‡æ£€ç´¢å’ŒBM25æ£€ç´¢çš„ä¼˜åŠ¿
    """
    
    def __init__(
        self,
        documents: List[str],
        vector_model: str = 'all-MiniLM-L6-v2',
        language: str = 'zh'
    ):
        """
        åˆå§‹åŒ–
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            vector_model: å‘é‡æ¨¡å‹åç§°
            language: è¯­è¨€
        """
        self.documents = documents
        
        # åˆå§‹åŒ–ä¸¤ä¸ªæ£€ç´¢å™¨
        if HAS_SENTENCE_TRANSFORMERS:
            self.vector_retriever = VectorRetriever(documents, vector_model)
        else:
            self.vector_retriever = None
            print("âš ï¸  å‘é‡æ£€ç´¢ä¸å¯ç”¨")
        
        if HAS_BM25:
            self.bm25_retriever = BM25Retriever(documents, language)
        else:
            self.bm25_retriever = None
            print("âš ï¸  BM25æ£€ç´¢ä¸å¯ç”¨")
    
    def search(
        self,
        query: str,
        top_k: int = 5,
        alpha: float = 0.5,
        use_rrf: bool = True
    ) -> List[SearchResult]:
        """
        æ··åˆæ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›æ•°é‡
            alpha: å‘é‡æ£€ç´¢æƒé‡ (0-1), BM25æƒé‡ä¸º1-alpha
            use_rrf: æ˜¯å¦ä½¿ç”¨RRF(Reciprocal Rank Fusion)
        
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        results = []
        
        # å‘é‡æ£€ç´¢
        if self.vector_retriever:
            vector_results = self.vector_retriever.search(query, top_k=top_k*2)
            results.append(('vector', vector_results))
        
        # BM25æ£€ç´¢
        if self.bm25_retriever:
            bm25_results = self.bm25_retriever.search(query, top_k=top_k*2)
            results.append(('bm25', bm25_results))
        
        if not results:
            return []
        
        # åˆå¹¶ç»“æœ
        if use_rrf:
            return self._merge_with_rrf(results, top_k)
        else:
            return self._merge_with_weighted_sum(results, top_k, alpha)
    
    def _merge_with_weighted_sum(
        self,
        results: List[Tuple[str, List[SearchResult]]],
        top_k: int,
        alpha: float
    ) -> List[SearchResult]:
        """
        åŠ æƒæ±‚å’Œåˆå¹¶
        
        Args:
            results: [(method, search_results), ...]
            top_k: è¿”å›æ•°é‡
            alpha: å‘é‡æƒé‡
        
        Returns:
            åˆå¹¶åçš„ç»“æœ
        """
        # å½’ä¸€åŒ–åˆ†æ•°
        normalized_results = []
        
        for method, search_results in results:
            if not search_results:
                continue
            
            scores = [r.score for r in search_results]
            min_score = min(scores)
            max_score = max(scores)
            
            if max_score == min_score:
                norm_scores = [1.0] * len(scores)
            else:
                norm_scores = [
                    (score - min_score) / (max_score - min_score)
                    for score in scores
                ]
            
            for result, norm_score in zip(search_results, norm_scores):
                normalized_results.append((method, result.document, norm_score))
        
        # åŠ æƒåˆå¹¶
        doc_scores = {}
        for method, doc, score in normalized_results:
            weight = alpha if method == 'vector' else (1 - alpha)
            if doc in doc_scores:
                doc_scores[doc] += weight * score
            else:
                doc_scores[doc] = weight * score
        
        # æ’åº
        sorted_docs = sorted(
            doc_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        # æ„å»ºç»“æœ
        final_results = []
        for doc, score in sorted_docs[:top_k]:
            final_results.append(SearchResult(
                document=doc,
                score=score,
                method='hybrid'
            ))
        
        return final_results
    
    def _merge_with_rrf(
        self,
        results: List[Tuple[str, List[SearchResult]]],
        top_k: int,
        k: int = 60
    ) -> List[SearchResult]:
        """
        ä½¿ç”¨RRF(Reciprocal Rank Fusion)åˆå¹¶
        
        RRFå…¬å¼: score = Î£ 1/(k + rank)
        
        Args:
            results: [(method, search_results), ...]
            top_k: è¿”å›æ•°é‡
            k: RRFå‚æ•° (é»˜è®¤60)
        
        Returns:
            åˆå¹¶åçš„ç»“æœ
        """
        doc_scores = {}
        
        for method, search_results in results:
            for rank, result in enumerate(search_results, start=1):
                doc = result.document
                rrf_score = 1.0 / (k + rank)
                
                if doc in doc_scores:
                    doc_scores[doc] += rrf_score
                else:
                    doc_scores[doc] = rrf_score
        
        # æ’åº
        sorted_docs = sorted(
            doc_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        # æ„å»ºç»“æœ
        final_results = []
        for doc, score in sorted_docs[:top_k]:
            final_results.append(SearchResult(
                document=doc,
                score=score,
                method='hybrid_rrf'
            ))
        
        return final_results


# ============= æµ‹è¯•ä»£ç  =============

def create_test_documents() -> List[str]:
    """åˆ›å»ºæµ‹è¯•æ–‡æ¡£"""
    return [
        "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€,é€‚åˆåˆå­¦è€…å­¦ä¹ ",
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯",
        "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥è§£å†³å¤æ‚é—®é¢˜",
        "è‡ªç„¶è¯­è¨€å¤„ç†(NLP)å¤„ç†äººç±»è¯­è¨€",
        "è®¡ç®—æœºè§†è§‰è®©æœºå™¨èƒ½å¤Ÿç†è§£å›¾åƒ",
        "å¼ºåŒ–å­¦ä¹ é€šè¿‡å¥–åŠ±æ¥è®­ç»ƒæ™ºèƒ½ä½“",
        "æ•°æ®ç§‘å­¦ç»“åˆç»Ÿè®¡å­¦å’Œç¼–ç¨‹æŠ€èƒ½",
        "äº‘è®¡ç®—æä¾›æŒ‰éœ€çš„è®¡ç®—èµ„æº",
        "åŒºå—é“¾æ˜¯ä¸€ç§åˆ†å¸ƒå¼è´¦æœ¬æŠ€æœ¯",
        "ç‰©è”ç½‘è¿æ¥ç‰©ç†è®¾å¤‡åˆ°äº’è”ç½‘"
    ]


def test_vector_retrieval():
    """æµ‹è¯•å‘é‡æ£€ç´¢"""
    if not HAS_SENTENCE_TRANSFORMERS:
        print("âš ï¸  è·³è¿‡å‘é‡æ£€ç´¢æµ‹è¯•(ç¼ºå°‘ä¾èµ–)")
        return
    
    print("=" * 60)
    print("æµ‹è¯•1: å‘é‡æ£€ç´¢")
    print("=" * 60)
    
    documents = create_test_documents()
    retriever = VectorRetriever(documents)
    
    # æµ‹è¯•æŸ¥è¯¢
    query = "å¦‚ä½•å­¦ä¹ äººå·¥æ™ºèƒ½?"
    print(f"\næŸ¥è¯¢: {query}")
    
    results = retriever.search(query, top_k=3)
    
    print(f"\næ‰¾åˆ°{len(results)}ä¸ªç›¸å…³æ–‡æ¡£:")
    for i, result in enumerate(results, 1):
        print(f"\n{i}. [åˆ†æ•°: {result.score:.3f}]")
        print(f"   {result.document}")
    
    print("\nâœ… å‘é‡æ£€ç´¢æµ‹è¯•å®Œæˆ!")


def test_bm25_retrieval():
    """æµ‹è¯•BM25æ£€ç´¢"""
    if not HAS_BM25:
        print("âš ï¸  è·³è¿‡BM25æ£€ç´¢æµ‹è¯•(ç¼ºå°‘ä¾èµ–)")
        return
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•2: BM25æ£€ç´¢")
    print("=" * 60)
    
    documents = create_test_documents()
    retriever = BM25Retriever(documents)
    
    # æµ‹è¯•æŸ¥è¯¢
    query = "æœºå™¨å­¦ä¹  æ·±åº¦å­¦ä¹ "
    print(f"\næŸ¥è¯¢: {query}")
    
    results = retriever.search(query, top_k=3)
    
    print(f"\næ‰¾åˆ°{len(results)}ä¸ªç›¸å…³æ–‡æ¡£:")
    for i, result in enumerate(results, 1):
        print(f"\n{i}. [åˆ†æ•°: {result.score:.3f}]")
        print(f"   {result.document}")
    
    print("\nâœ… BM25æ£€ç´¢æµ‹è¯•å®Œæˆ!")


def test_hybrid_retrieval():
    """æµ‹è¯•æ··åˆæ£€ç´¢"""
    if not (HAS_SENTENCE_TRANSFORMERS and HAS_BM25):
        print("âš ï¸  è·³è¿‡æ··åˆæ£€ç´¢æµ‹è¯•(ç¼ºå°‘ä¾èµ–)")
        return
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•3: æ··åˆæ£€ç´¢")
    print("=" * 60)
    
    documents = create_test_documents()
    retriever = HybridRetriever(documents)
    
    # æµ‹è¯•æŸ¥è¯¢
    query = "å­¦ä¹ ç¼–ç¨‹å’Œæœºå™¨å­¦ä¹ "
    print(f"\næŸ¥è¯¢: {query}")
    
    # æµ‹è¯•åŠ æƒæ±‚å’Œ
    print("\næ–¹æ³•1: åŠ æƒæ±‚å’Œ (alpha=0.5)")
    results_weighted = retriever.search(query, top_k=3, alpha=0.5, use_rrf=False)
    
    print(f"\næ‰¾åˆ°{len(results_weighted)}ä¸ªç›¸å…³æ–‡æ¡£:")
    for i, result in enumerate(results_weighted, 1):
        print(f"\n{i}. [åˆ†æ•°: {result.score:.3f}, æ–¹æ³•: {result.method}]")
        print(f"   {result.document}")
    
    # æµ‹è¯•RRF
    print("\næ–¹æ³•2: RRFèåˆ")
    results_rrf = retriever.search(query, top_k=3, use_rrf=True)
    
    print(f"\næ‰¾åˆ°{len(results_rrf)}ä¸ªç›¸å…³æ–‡æ¡£:")
    for i, result in enumerate(results_rrf, 1):
        print(f"\n{i}. [åˆ†æ•°: {result.score:.3f}, æ–¹æ³•: {result.method}]")
        print(f"   {result.document}")
    
    print("\nâœ… æ··åˆæ£€ç´¢æµ‹è¯•å®Œæˆ!")


def test_comparison():
    """å¯¹æ¯”ä¸‰ç§æ£€ç´¢æ–¹æ³•"""
    if not (HAS_SENTENCE_TRANSFORMERS and HAS_BM25):
        print("âš ï¸  è·³è¿‡å¯¹æ¯”æµ‹è¯•(ç¼ºå°‘ä¾èµ–)")
        return
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•4: æ£€ç´¢æ–¹æ³•å¯¹æ¯”")
    print("=" * 60)
    
    documents = create_test_documents()
    
    # åˆ›å»ºä¸‰ç§æ£€ç´¢å™¨
    vector_retriever = VectorRetriever(documents)
    bm25_retriever = BM25Retriever(documents)
    hybrid_retriever = HybridRetriever(documents)
    
    # æµ‹è¯•æŸ¥è¯¢
    query = "Pythonç¼–ç¨‹"
    print(f"\næŸ¥è¯¢: {query}\n")
    
    # å‘é‡æ£€ç´¢
    print("å‘é‡æ£€ç´¢ç»“æœ:")
    vector_results = vector_retriever.search(query, top_k=3)
    for result in vector_results:
        print(f"  {result.score:.3f} - {result.document[:40]}...")
    
    # BM25æ£€ç´¢
    print("\nBM25æ£€ç´¢ç»“æœ:")
    bm25_results = bm25_retriever.search(query, top_k=3)
    for result in bm25_results:
        print(f"  {result.score:.3f} - {result.document[:40]}...")
    
    # æ··åˆæ£€ç´¢
    print("\næ··åˆæ£€ç´¢ç»“æœ:")
    hybrid_results = hybrid_retriever.search(query, top_k=3)
    for result in hybrid_results:
        print(f"  {result.score:.3f} - {result.document[:40]}...")
    
    print("\nâœ… å¯¹æ¯”æµ‹è¯•å®Œæˆ!")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\nğŸš€ å¼€å§‹æµ‹è¯•é«˜çº§æ£€ç´¢ç³»ç»Ÿ...\n")
    
    test_vector_retrieval()
    test_bm25_retrieval()
    test_hybrid_retrieval()
    test_comparison()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print("=" * 60)
    
    print("\nğŸ’¡ æ€»ç»“:")
    print("  - å‘é‡æ£€ç´¢: æ“…é•¿è¯­ä¹‰ç†è§£")
    print("  - BM25æ£€ç´¢: æ“…é•¿å…³é”®è¯åŒ¹é…")
    print("  - æ··åˆæ£€ç´¢: ç»“åˆä¸¤è€…ä¼˜åŠ¿,æ•ˆæœæœ€ä½³")


if __name__ == "__main__":
    run_all_tests()
