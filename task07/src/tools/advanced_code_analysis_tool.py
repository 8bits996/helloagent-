"""
é«˜çº§ä»£ç åˆ†æå·¥å…· - æ”¯æŒå¤šç»´åº¦ä»£ç è´¨é‡æ£€æŸ¥
"""

import os
import re
import ast
import json
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path


class AnalysisDimension(Enum):
    """åˆ†æç»´åº¦"""
    SECURITY = "security"
    PERFORMANCE = "performance"
    STYLE = "style"
    COMPLEXITY = "complexity"
    BUG_RISK = "bug_risk"


class IssueSeverity(Enum):
    """é—®é¢˜ä¸¥é‡ç¨‹åº¦"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


@dataclass
class CodeIssue:
    """ä»£ç é—®é¢˜æ•°æ®ç»“æ„"""
    dimension: AnalysisDimension
    severity: IssueSeverity
    message: str
    line: int
    column: int = 0
    code_snippet: str = ""
    rule_id: str = ""
    suggestion: str = ""
    
    def to_dict(self) -> Dict:
        return {
            'dimension': self.dimension.value,
            'severity': self.severity.value,
            'message': self.message,
            'line': self.line,
            'column': self.column,
            'code_snippet': self.code_snippet,
            'rule_id': self.rule_id,
            'suggestion': self.suggestion
        }


class AdvancedCodeAnalysisTool:
    """é«˜çº§ä»£ç åˆ†æå·¥å…·"""
    
    name = "code_analysis"
    description = "é«˜çº§ä»£ç åˆ†æå·¥å…·ï¼Œæ”¯æŒå®‰å…¨ã€æ€§èƒ½ã€é£æ ¼ã€å¤æ‚åº¦å’ŒBugé£é™©äº”ç»´åº¦åˆ†æ"
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        
        # é»˜è®¤é…ç½®
        self.max_line_length = self.config.get('max_line_length', 120)
        self.max_function_length = self.config.get('max_function_length', 50)
        self.max_complexity = self.config.get('max_complexity', 10)
        self.max_parameters = self.config.get('max_parameters', 5)
        self.max_nesting_depth = self.config.get('max_nesting_depth', 4)
        
        # å®‰å…¨è§„åˆ™
        self.security_rules = self._init_security_rules()
        
        # æ€§èƒ½è§„åˆ™
        self.performance_rules = self._init_performance_rules()
        
        # é£æ ¼è§„åˆ™
        self.style_rules = self._init_style_rules()
    
    def get_parameters(self) -> Dict:
        return {
            "path": {
                "type": "str",
                "description": "è¦åˆ†æçš„æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„",
                "required": False
            },
            "content": {
                "type": "str",
                "description": "è¦åˆ†æçš„ä»£ç å†…å®¹",
                "required": False
            },
            "dimensions": {
                "type": "list",
                "description": "åˆ†æç»´åº¦åˆ—è¡¨ï¼šsecurity, performance, style, complexity, bug_risk",
                "required": False,
                "default": ["security", "performance", "style", "complexity", "bug_risk"]
            },
            "output_format": {
                "type": "str",
                "description": "è¾“å‡ºæ ¼å¼ï¼šjson, text, markdown",
                "required": False,
                "default": "text"
            }
        }
    
    def run(self, parameters: Dict) -> str:
        """è¿è¡Œä»£ç åˆ†æ"""
        if isinstance(parameters, str):
            # ç®€å•æ¨¡å¼ï¼šç›´æ¥åˆ†æä»£ç 
            return self._analyze_and_format(parameters, None, ['security', 'performance', 'style', 'complexity', 'bug_risk'], 'text')
        
        path = parameters.get('path')
        content = parameters.get('content')
        dimensions = parameters.get('dimensions', ['security', 'performance', 'style', 'complexity', 'bug_risk'])
        output_format = parameters.get('output_format', 'text')
        
        if path:
            path = Path(path)
            if path.is_file():
                with open(path, 'r', encoding='utf-8') as f:
                    content = f.read()
            elif path.is_dir():
                return self._analyze_directory(path, dimensions, output_format)
            else:
                return f"é”™è¯¯ï¼šè·¯å¾„ä¸å­˜åœ¨ - {path}"
        
        if not content:
            return "é”™è¯¯ï¼šè¯·æä¾›ä»£ç å†…å®¹æˆ–æœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„"
        
        return self._analyze_and_format(content, str(path) if path else None, dimensions, output_format)
    
    def _analyze_and_format(self, content: str, filepath: Optional[str], dimensions: List[str], output_format: str) -> str:
        """åˆ†æå¹¶æ ¼å¼åŒ–ç»“æœ"""
        result = self.analyze(content, filepath, dimensions)
        
        if output_format == 'json':
            return json.dumps(result, ensure_ascii=False, indent=2)
        elif output_format == 'markdown':
            return self._format_markdown(result)
        else:
            return self._format_text(result)
    
    def analyze(self, content: str, filepath: Optional[str] = None, dimensions: Optional[List[str]] = None) -> Dict[str, Any]:
        """æ‰§è¡Œä»£ç åˆ†æ"""
        dimensions = dimensions or ['security', 'performance', 'style', 'complexity', 'bug_risk']
        
        result = {
            'filepath': filepath,
            'issues': [],
            'metrics': {},
            'summary': {}
        }
        
        lines = content.split('\n')
        
        # åŸºç¡€æŒ‡æ ‡
        result['metrics'] = self._calculate_metrics(content, lines)
        
        # æŒ‰ç»´åº¦åˆ†æ
        if 'security' in dimensions:
            result['issues'].extend(self._analyze_security(content, lines))
        
        if 'performance' in dimensions:
            result['issues'].extend(self._analyze_performance(content, lines))
        
        if 'style' in dimensions:
            result['issues'].extend(self._analyze_style(content, lines))
        
        if 'complexity' in dimensions:
            complexity_issues, complexity_metrics = self._analyze_complexity(content)
            result['issues'].extend(complexity_issues)
            result['metrics']['complexity'] = complexity_metrics
        
        if 'bug_risk' in dimensions:
            result['issues'].extend(self._analyze_bug_risk(content, lines))
        
        # ç”Ÿæˆæ‘˜è¦
        result['summary'] = self._generate_summary(result)
        
        return result
    
    def _calculate_metrics(self, content: str, lines: List[str]) -> Dict[str, Any]:
        """è®¡ç®—ä»£ç æŒ‡æ ‡"""
        code_lines = [l for l in lines if l.strip() and not l.strip().startswith('#')]
        comment_lines = [l for l in lines if l.strip().startswith('#')]
        
        return {
            'total_lines': len(lines),
            'code_lines': len(code_lines),
            'comment_lines': len(comment_lines),
            'blank_lines': len([l for l in lines if not l.strip()]),
            'comment_ratio': len(comment_lines) / len(code_lines) if code_lines else 0,
            'average_line_length': sum(len(l) for l in code_lines) / len(code_lines) if code_lines else 0
        }
    
    def _analyze_security(self, content: str, lines: List[str]) -> List[CodeIssue]:
        """å®‰å…¨åˆ†æ"""
        issues = []
        
        for rule_id, rule in self.security_rules.items():
            pattern = rule['pattern']
            for i, line in enumerate(lines, 1):
                if re.search(pattern, line, re.IGNORECASE):
                    issues.append(CodeIssue(
                        dimension=AnalysisDimension.SECURITY,
                        severity=IssueSeverity[rule['severity'].upper()],
                        message=rule['message'],
                        line=i,
                        code_snippet=line.strip()[:100],
                        rule_id=rule_id,
                        suggestion=rule.get('suggestion', '')
                    ))
        
        return issues
    
    def _analyze_performance(self, content: str, lines: List[str]) -> List[CodeIssue]:
        """æ€§èƒ½åˆ†æ"""
        issues = []
        
        for rule_id, rule in self.performance_rules.items():
            pattern = rule['pattern']
            for i, line in enumerate(lines, 1):
                if re.search(pattern, line, re.IGNORECASE):
                    issues.append(CodeIssue(
                        dimension=AnalysisDimension.PERFORMANCE,
                        severity=IssueSeverity[rule['severity'].upper()],
                        message=rule['message'],
                        line=i,
                        code_snippet=line.strip()[:100],
                        rule_id=rule_id,
                        suggestion=rule.get('suggestion', '')
                    ))
        
        return issues
    
    def _analyze_style(self, content: str, lines: List[str]) -> List[CodeIssue]:
        """é£æ ¼åˆ†æ"""
        issues = []
        
        for i, line in enumerate(lines, 1):
            # è¡Œé•¿åº¦æ£€æŸ¥
            if len(line) > self.max_line_length:
                issues.append(CodeIssue(
                    dimension=AnalysisDimension.STYLE,
                    severity=IssueSeverity.WARNING,
                    message=f"è¡Œé•¿åº¦è¶…è¿‡ {self.max_line_length} å­—ç¬¦ ({len(line)} å­—ç¬¦)",
                    line=i,
                    rule_id='line_length',
                    suggestion=f"å°†è¡Œæ‹†åˆ†ä¸ºå¤šè¡Œï¼Œä¿æŒæ¯è¡Œä¸è¶…è¿‡ {self.max_line_length} å­—ç¬¦"
                ))
            
            # å°¾éšç©ºç™½
            if line.rstrip() != line and line.strip():
                issues.append(CodeIssue(
                    dimension=AnalysisDimension.STYLE,
                    severity=IssueSeverity.INFO,
                    message="è¡Œå°¾æœ‰å¤šä½™ç©ºç™½",
                    line=i,
                    rule_id='trailing_whitespace',
                    suggestion="åˆ é™¤è¡Œå°¾çš„ç©ºç™½å­—ç¬¦"
                ))
            
            # æ··åˆç¼©è¿›
            if line.startswith(' ') and '\t' in line[:len(line) - len(line.lstrip())]:
                issues.append(CodeIssue(
                    dimension=AnalysisDimension.STYLE,
                    severity=IssueSeverity.WARNING,
                    message="æ··åˆä½¿ç”¨ç©ºæ ¼å’Œåˆ¶è¡¨ç¬¦ç¼©è¿›",
                    line=i,
                    rule_id='mixed_indentation',
                    suggestion="ç»Ÿä¸€ä½¿ç”¨ç©ºæ ¼æˆ–åˆ¶è¡¨ç¬¦è¿›è¡Œç¼©è¿›"
                ))
        
        # åº”ç”¨è‡ªå®šä¹‰é£æ ¼è§„åˆ™
        for rule_id, rule in self.style_rules.items():
            pattern = rule['pattern']
            for i, line in enumerate(lines, 1):
                if re.search(pattern, line):
                    issues.append(CodeIssue(
                        dimension=AnalysisDimension.STYLE,
                        severity=IssueSeverity[rule['severity'].upper()],
                        message=rule['message'],
                        line=i,
                        code_snippet=line.strip()[:100],
                        rule_id=rule_id,
                        suggestion=rule.get('suggestion', '')
                    ))
        
        return issues
    
    def _analyze_complexity(self, content: str) -> Tuple[List[CodeIssue], Dict]:
        """å¤æ‚åº¦åˆ†æ"""
        issues = []
        metrics = {
            'functions': [],
            'classes': [],
            'average_complexity': 0,
            'max_complexity': 0
        }
        
        try:
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    complexity = self._calculate_cyclomatic_complexity(node)
                    func_lines = (node.end_lineno - node.lineno + 1) if hasattr(node, 'end_lineno') else 0
                    param_count = len(node.args.args)
                    nesting_depth = self._calculate_nesting_depth(node)
                    
                    func_info = {
                        'name': node.name,
                        'line': node.lineno,
                        'complexity': complexity,
                        'lines': func_lines,
                        'parameters': param_count,
                        'nesting_depth': nesting_depth
                    }
                    metrics['functions'].append(func_info)
                    
                    # æ£€æŸ¥å¤æ‚åº¦
                    if complexity > self.max_complexity:
                        issues.append(CodeIssue(
                            dimension=AnalysisDimension.COMPLEXITY,
                            severity=IssueSeverity.WARNING if complexity <= self.max_complexity * 1.5 else IssueSeverity.ERROR,
                            message=f"å‡½æ•° '{node.name}' åœˆå¤æ‚åº¦è¿‡é«˜ ({complexity}ï¼Œé˜ˆå€¼ {self.max_complexity})",
                            line=node.lineno,
                            rule_id='high_complexity',
                            suggestion="è€ƒè™‘å°†å‡½æ•°æ‹†åˆ†ä¸ºæ›´å°çš„å‡½æ•°ï¼Œæˆ–ç®€åŒ–æ¡ä»¶é€»è¾‘"
                        ))
                    
                    # æ£€æŸ¥å‡½æ•°é•¿åº¦
                    if func_lines > self.max_function_length:
                        issues.append(CodeIssue(
                            dimension=AnalysisDimension.COMPLEXITY,
                            severity=IssueSeverity.WARNING,
                            message=f"å‡½æ•° '{node.name}' è¿‡é•¿ ({func_lines} è¡Œï¼Œé˜ˆå€¼ {self.max_function_length})",
                            line=node.lineno,
                            rule_id='function_length',
                            suggestion="å°†å‡½æ•°æ‹†åˆ†ä¸ºæ›´å°çš„è¾…åŠ©å‡½æ•°"
                        ))
                    
                    # æ£€æŸ¥å‚æ•°æ•°é‡
                    if param_count > self.max_parameters:
                        issues.append(CodeIssue(
                            dimension=AnalysisDimension.COMPLEXITY,
                            severity=IssueSeverity.WARNING,
                            message=f"å‡½æ•° '{node.name}' å‚æ•°è¿‡å¤š ({param_count} ä¸ªï¼Œé˜ˆå€¼ {self.max_parameters})",
                            line=node.lineno,
                            rule_id='too_many_parameters',
                            suggestion="è€ƒè™‘ä½¿ç”¨å¯¹è±¡æˆ–å­—å…¸å°è£…å‚æ•°"
                        ))
                    
                    # æ£€æŸ¥åµŒå¥—æ·±åº¦
                    if nesting_depth > self.max_nesting_depth:
                        issues.append(CodeIssue(
                            dimension=AnalysisDimension.COMPLEXITY,
                            severity=IssueSeverity.WARNING,
                            message=f"å‡½æ•° '{node.name}' åµŒå¥—å±‚çº§è¿‡æ·± ({nesting_depth} å±‚ï¼Œé˜ˆå€¼ {self.max_nesting_depth})",
                            line=node.lineno,
                            rule_id='deep_nesting',
                            suggestion="ä½¿ç”¨æ—©è¿”å›(early return)æˆ–æå–å­å‡½æ•°æ¥å‡å°‘åµŒå¥—"
                        ))
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£å­—ç¬¦ä¸²
                    if not ast.get_docstring(node):
                        issues.append(CodeIssue(
                            dimension=AnalysisDimension.COMPLEXITY,
                            severity=IssueSeverity.INFO,
                            message=f"å‡½æ•° '{node.name}' ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²",
                            line=node.lineno,
                            rule_id='missing_docstring',
                            suggestion="æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²è¯´æ˜å‡½æ•°çš„ç”¨é€”ã€å‚æ•°å’Œè¿”å›å€¼"
                        ))
                
                elif isinstance(node, ast.ClassDef):
                    methods = [n for n in node.body if isinstance(n, ast.FunctionDef)]
                    metrics['classes'].append({
                        'name': node.name,
                        'line': node.lineno,
                        'method_count': len(methods),
                        'has_docstring': ast.get_docstring(node) is not None
                    })
            
            # è®¡ç®—å¹³å‡å¤æ‚åº¦
            if metrics['functions']:
                complexities = [f['complexity'] for f in metrics['functions']]
                metrics['average_complexity'] = sum(complexities) / len(complexities)
                metrics['max_complexity'] = max(complexities)
            
        except SyntaxError as e:
            issues.append(CodeIssue(
                dimension=AnalysisDimension.COMPLEXITY,
                severity=IssueSeverity.CRITICAL,
                message=f"è¯­æ³•é”™è¯¯: {str(e)}",
                line=e.lineno or 0,
                rule_id='syntax_error'
            ))
        
        return issues, metrics
    
    def _analyze_bug_risk(self, content: str, lines: List[str]) -> List[CodeIssue]:
        """Bugé£é™©åˆ†æ"""
        issues = []
        
        bug_patterns = {
            'mutable_default': {
                'pattern': r'def\s+\w+\s*\([^)]*=\s*(\[\]|\{\}|\[\s*\]|\{\s*\})',
                'message': 'ä½¿ç”¨å¯å˜å¯¹è±¡ä½œä¸ºé»˜è®¤å‚æ•°å€¼',
                'severity': 'warning',
                'suggestion': 'ä½¿ç”¨ None ä½œä¸ºé»˜è®¤å€¼ï¼Œç„¶ååœ¨å‡½æ•°å†…éƒ¨åˆå§‹åŒ–'
            },
            'bare_except': {
                'pattern': r'except\s*:',
                'message': 'ä½¿ç”¨è£¸exceptæ•è·æ‰€æœ‰å¼‚å¸¸',
                'severity': 'warning',
                'suggestion': 'æ˜ç¡®æŒ‡å®šè¦æ•è·çš„å¼‚å¸¸ç±»å‹'
            },
            'assert_tuple': {
                'pattern': r'assert\s*\([^)]+,[^)]+\)',
                'message': 'assertè¯­å¥ä½¿ç”¨å…ƒç»„ï¼ˆæ€»æ˜¯ä¸ºTrueï¼‰',
                'severity': 'error',
                'suggestion': 'ç§»é™¤assertåçš„æ‹¬å·ï¼Œæˆ–ä½¿ç”¨é€—å·åˆ†éš”æ¡ä»¶å’Œæ¶ˆæ¯'
            },
            'comparison_to_none': {
                'pattern': r'==\s*None|!=\s*None',
                'message': 'ä½¿ç”¨==æˆ–!=ä¸Noneæ¯”è¾ƒ',
                'severity': 'info',
                'suggestion': 'ä½¿ç”¨ is None æˆ– is not None'
            },
            'comparison_to_true': {
                'pattern': r'==\s*True|==\s*False',
                'message': 'ä½¿ç”¨==ä¸True/Falseæ¯”è¾ƒ',
                'severity': 'info',
                'suggestion': 'ç›´æ¥ä½¿ç”¨å¸ƒå°”è¡¨è¾¾å¼æˆ–ä½¿ç”¨ is'
            },
            'string_concat_in_loop': {
                'pattern': r'for\s+.*:\s*\n\s+\w+\s*\+=\s*["\']',
                'message': 'åœ¨å¾ªç¯ä¸­ä½¿ç”¨å­—ç¬¦ä¸²æ‹¼æ¥',
                'severity': 'warning',
                'suggestion': 'ä½¿ç”¨åˆ—è¡¨æ”¶é›†å­—ç¬¦ä¸²ï¼Œæœ€åç”¨joinè¿æ¥'
            },
            'unused_variable': {
                'pattern': r'^\s*\w+\s*=\s*[^=].*$',
                'message': 'å¯èƒ½æœªä½¿ç”¨çš„å˜é‡èµ‹å€¼',
                'severity': 'info',
                'suggestion': 'æ£€æŸ¥å˜é‡æ˜¯å¦è¢«ä½¿ç”¨ï¼Œæœªä½¿ç”¨åˆ™åˆ é™¤'
            },
            'shadowing_builtin': {
                'pattern': r'\b(list|dict|str|int|float|bool|set|tuple|type|id|input|print|len|range|map|filter|sum|min|max|open|file|dir|help|vars|locals|globals)\s*=',
                'message': 'å˜é‡åè¦†ç›–äº†Pythonå†…ç½®åç§°',
                'severity': 'warning',
                'suggestion': 'ä½¿ç”¨ä¸åŒçš„å˜é‡åé¿å…è¦†ç›–å†…ç½®åç§°'
            },
        }
        
        for rule_id, rule in bug_patterns.items():
            pattern = rule['pattern']
            for i, line in enumerate(lines, 1):
                if re.search(pattern, line):
                    # æ’é™¤æ³¨é‡Š
                    if line.strip().startswith('#'):
                        continue
                    
                    issues.append(CodeIssue(
                        dimension=AnalysisDimension.BUG_RISK,
                        severity=IssueSeverity[rule['severity'].upper()],
                        message=rule['message'],
                        line=i,
                        code_snippet=line.strip()[:100],
                        rule_id=rule_id,
                        suggestion=rule.get('suggestion', '')
                    ))
        
        return issues
    
    def _calculate_cyclomatic_complexity(self, node: ast.AST) -> int:
        """è®¡ç®—åœˆå¤æ‚åº¦"""
        complexity = 1
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.ExceptHandler, ast.With)):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
            elif isinstance(child, ast.comprehension):
                complexity += 1
                if child.ifs:
                    complexity += len(child.ifs)
            elif isinstance(child, ast.Assert):
                complexity += 1
        
        return complexity
    
    def _calculate_nesting_depth(self, node: ast.AST) -> int:
        """è®¡ç®—æœ€å¤§åµŒå¥—æ·±åº¦"""
        def get_depth(node, current_depth=0):
            max_depth = current_depth
            
            for child in ast.iter_child_nodes(node):
                if isinstance(child, (ast.If, ast.While, ast.For, ast.With, ast.Try)):
                    child_depth = get_depth(child, current_depth + 1)
                    max_depth = max(max_depth, child_depth)
                else:
                    child_depth = get_depth(child, current_depth)
                    max_depth = max(max_depth, child_depth)
            
            return max_depth
        
        return get_depth(node)
    
    def _generate_summary(self, result: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        issues = result['issues']
        
        # æŒ‰ç»´åº¦ç»Ÿè®¡
        by_dimension = {}
        for dim in AnalysisDimension:
            dim_issues = [i for i in issues if i.dimension == dim]
            by_dimension[dim.value] = {
                'total': len(dim_issues),
                'critical': len([i for i in dim_issues if i.severity == IssueSeverity.CRITICAL]),
                'error': len([i for i in dim_issues if i.severity == IssueSeverity.ERROR]),
                'warning': len([i for i in dim_issues if i.severity == IssueSeverity.WARNING]),
                'info': len([i for i in dim_issues if i.severity == IssueSeverity.INFO])
            }
        
        # è®¡ç®—è´¨é‡åˆ†æ•°
        quality_score = 100.0
        for issue in issues:
            if issue.severity == IssueSeverity.CRITICAL:
                quality_score -= 20
            elif issue.severity == IssueSeverity.ERROR:
                quality_score -= 10
            elif issue.severity == IssueSeverity.WARNING:
                quality_score -= 3
            elif issue.severity == IssueSeverity.INFO:
                quality_score -= 0.5
        
        quality_score = max(0, min(100, quality_score))
        
        # ç¡®å®šæ•´ä½“ç­‰çº§
        if quality_score >= 90:
            grade = 'A'
        elif quality_score >= 80:
            grade = 'B'
        elif quality_score >= 70:
            grade = 'C'
        elif quality_score >= 60:
            grade = 'D'
        else:
            grade = 'F'
        
        return {
            'total_issues': len(issues),
            'by_severity': {
                'critical': len([i for i in issues if i.severity == IssueSeverity.CRITICAL]),
                'error': len([i for i in issues if i.severity == IssueSeverity.ERROR]),
                'warning': len([i for i in issues if i.severity == IssueSeverity.WARNING]),
                'info': len([i for i in issues if i.severity == IssueSeverity.INFO])
            },
            'by_dimension': by_dimension,
            'quality_score': round(quality_score, 1),
            'grade': grade
        }
    
    def _format_text(self, result: Dict) -> str:
        """æ ¼å¼åŒ–ä¸ºæ–‡æœ¬è¾“å‡º"""
        lines = []
        
        lines.append("=" * 60)
        lines.append("ä»£ç åˆ†ææŠ¥å‘Š")
        lines.append("=" * 60)
        
        if result.get('filepath'):
            lines.append(f"æ–‡ä»¶: {result['filepath']}")
        
        # æ‘˜è¦
        summary = result.get('summary', {})
        lines.append(f"\nğŸ“Š è´¨é‡è¯„åˆ†: {summary.get('quality_score', 0)}/100 (ç­‰çº§: {summary.get('grade', 'N/A')})")
        lines.append(f"ğŸ“ æ€»é—®é¢˜æ•°: {summary.get('total_issues', 0)}")
        
        by_severity = summary.get('by_severity', {})
        lines.append(f"   - ä¸¥é‡: {by_severity.get('critical', 0)}")
        lines.append(f"   - é”™è¯¯: {by_severity.get('error', 0)}")
        lines.append(f"   - è­¦å‘Š: {by_severity.get('warning', 0)}")
        lines.append(f"   - æç¤º: {by_severity.get('info', 0)}")
        
        # æŒ‡æ ‡
        metrics = result.get('metrics', {})
        lines.append(f"\nğŸ“ˆ ä»£ç æŒ‡æ ‡:")
        lines.append(f"   - æ€»è¡Œæ•°: {metrics.get('total_lines', 0)}")
        lines.append(f"   - ä»£ç è¡Œ: {metrics.get('code_lines', 0)}")
        lines.append(f"   - æ³¨é‡Šè¡Œ: {metrics.get('comment_lines', 0)}")
        
        if 'complexity' in metrics:
            comp = metrics['complexity']
            lines.append(f"   - å¹³å‡å¤æ‚åº¦: {comp.get('average_complexity', 0):.1f}")
            lines.append(f"   - æœ€å¤§å¤æ‚åº¦: {comp.get('max_complexity', 0)}")
        
        # é—®é¢˜è¯¦æƒ…
        issues = result.get('issues', [])
        if issues:
            lines.append(f"\nğŸ” é—®é¢˜è¯¦æƒ…:")
            
            # æŒ‰ç»´åº¦åˆ†ç»„
            for dim in AnalysisDimension:
                dim_issues = [i for i in issues if i.dimension == dim]
                if dim_issues:
                    lines.append(f"\n  [{dim.value.upper()}]")
                    for issue in dim_issues[:10]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                        severity_icon = {'critical': 'ğŸ”´', 'error': 'ğŸŸ ', 'warning': 'ğŸŸ¡', 'info': 'ğŸ”µ'}.get(issue.severity.value, 'âšª')
                        lines.append(f"    {severity_icon} è¡Œ {issue.line}: {issue.message}")
                        if issue.suggestion:
                            lines.append(f"       ğŸ’¡ å»ºè®®: {issue.suggestion}")
        
        lines.append("\n" + "=" * 60)
        
        return "\n".join(lines)
    
    def _format_markdown(self, result: Dict) -> str:
        """æ ¼å¼åŒ–ä¸ºMarkdownè¾“å‡º"""
        lines = []
        
        lines.append("# ä»£ç åˆ†ææŠ¥å‘Š\n")
        
        if result.get('filepath'):
            lines.append(f"**æ–‡ä»¶**: `{result['filepath']}`\n")
        
        # æ‘˜è¦
        summary = result.get('summary', {})
        lines.append("## ğŸ“Š æ‘˜è¦\n")
        lines.append(f"| æŒ‡æ ‡ | å€¼ |")
        lines.append(f"|------|-----|")
        lines.append(f"| è´¨é‡è¯„åˆ† | {summary.get('quality_score', 0)}/100 |")
        lines.append(f"| ç­‰çº§ | {summary.get('grade', 'N/A')} |")
        lines.append(f"| æ€»é—®é¢˜æ•° | {summary.get('total_issues', 0)} |")
        
        by_severity = summary.get('by_severity', {})
        lines.append(f"| ä¸¥é‡é—®é¢˜ | {by_severity.get('critical', 0)} |")
        lines.append(f"| é”™è¯¯ | {by_severity.get('error', 0)} |")
        lines.append(f"| è­¦å‘Š | {by_severity.get('warning', 0)} |")
        lines.append(f"| æç¤º | {by_severity.get('info', 0)} |")
        lines.append("")
        
        # é—®é¢˜è¯¦æƒ…
        issues = result.get('issues', [])
        if issues:
            lines.append("## ğŸ” é—®é¢˜è¯¦æƒ…\n")
            
            for dim in AnalysisDimension:
                dim_issues = [i for i in issues if i.dimension == dim]
                if dim_issues:
                    lines.append(f"### {dim.value.title()}\n")
                    
                    for issue in dim_issues:
                        severity_badge = {'critical': 'ğŸ”´', 'error': 'ğŸŸ ', 'warning': 'ğŸŸ¡', 'info': 'ğŸ”µ'}.get(issue.severity.value, 'âšª')
                        lines.append(f"- {severity_badge} **è¡Œ {issue.line}**: {issue.message}")
                        if issue.suggestion:
                            lines.append(f"  - ğŸ’¡ *{issue.suggestion}*")
                    
                    lines.append("")
        
        return "\n".join(lines)
    
    def _analyze_directory(self, path: Path, dimensions: List[str], output_format: str) -> str:
        """åˆ†ææ•´ä¸ªç›®å½•"""
        results = []
        
        for file_path in path.rglob('*.py'):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                result = self.analyze(content, str(file_path), dimensions)
                results.append(result)
            except Exception as e:
                results.append({
                    'filepath': str(file_path),
                    'error': str(e)
                })
        
        # æ±‡æ€»ç»“æœ
        total_issues = sum(len(r.get('issues', [])) for r in results)
        total_files = len(results)
        
        summary = {
            'directory': str(path),
            'total_files': total_files,
            'total_issues': total_issues,
            'files': results
        }
        
        if output_format == 'json':
            return json.dumps(summary, ensure_ascii=False, indent=2, default=lambda x: x.to_dict() if hasattr(x, 'to_dict') else str(x))
        else:
            lines = [f"ç›®å½•åˆ†æ: {path}", f"æ–‡ä»¶æ•°: {total_files}", f"æ€»é—®é¢˜æ•°: {total_issues}", ""]
            for r in results:
                lines.append(f"\n--- {r.get('filepath', 'Unknown')} ---")
                if 'error' in r:
                    lines.append(f"é”™è¯¯: {r['error']}")
                else:
                    s = r.get('summary', {})
                    lines.append(f"è¯„åˆ†: {s.get('quality_score', 0)}/100, é—®é¢˜: {s.get('total_issues', 0)}")
            return "\n".join(lines)
    
    def _init_security_rules(self) -> Dict:
        """åˆå§‹åŒ–å®‰å…¨è§„åˆ™"""
        return {
            'sql_injection_format': {
                'pattern': r'execute\s*\(\s*["\'].*%s',
                'message': 'SQLæ³¨å…¥é£é™©ï¼šä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼åŒ–æ„å»ºSQL',
                'severity': 'critical',
                'suggestion': 'ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢ï¼Œå¦‚ cursor.execute("SELECT * FROM users WHERE id = ?", (user_id,))'
            },
            'sql_injection_fstring': {
                'pattern': r'execute\s*\(\s*f["\']',
                'message': 'SQLæ³¨å…¥é£é™©ï¼šä½¿ç”¨f-stringæ„å»ºSQL',
                'severity': 'critical',
                'suggestion': 'ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢è€Œä¸æ˜¯f-string'
            },
            'sql_injection_concat': {
                'pattern': r'cursor\.execute\s*\([^,]+\+',
                'message': 'SQLæ³¨å…¥é£é™©ï¼šå­—ç¬¦ä¸²æ‹¼æ¥æ„å»ºSQL',
                'severity': 'critical',
                'suggestion': 'ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢è€Œä¸æ˜¯å­—ç¬¦ä¸²æ‹¼æ¥'
            },
            'command_injection_system': {
                'pattern': r'os\.system\s*\(',
                'message': 'å‘½ä»¤æ³¨å…¥é£é™©ï¼šä½¿ç”¨os.system',
                'severity': 'critical',
                'suggestion': 'ä½¿ç”¨subprocessæ¨¡å—å¹¶é¿å…shell=True'
            },
            'command_injection_shell': {
                'pattern': r'subprocess\.(call|run|Popen)\s*\([^)]*shell\s*=\s*True',
                'message': 'å‘½ä»¤æ³¨å…¥é£é™©ï¼šshell=True',
                'severity': 'critical',
                'suggestion': 'é¿å…ä½¿ç”¨shell=Trueï¼Œä¼ å…¥å‘½ä»¤åˆ—è¡¨'
            },
            'code_injection_eval': {
                'pattern': r'\beval\s*\(',
                'message': 'ä»£ç æ³¨å…¥é£é™©ï¼šä½¿ç”¨eval',
                'severity': 'critical',
                'suggestion': 'é¿å…ä½¿ç”¨evalï¼Œä½¿ç”¨ast.literal_evalæˆ–å…¶ä»–å®‰å…¨æ›¿ä»£æ–¹æ¡ˆ'
            },
            'code_injection_exec': {
                'pattern': r'\bexec\s*\(',
                'message': 'ä»£ç æ³¨å…¥é£é™©ï¼šä½¿ç”¨exec',
                'severity': 'critical',
                'suggestion': 'é¿å…ä½¿ç”¨execï¼Œé‡æ–°è®¾è®¡ä»£ç é€»è¾‘'
            },
            'hardcoded_password': {
                'pattern': r'password\s*=\s*["\'][^"\']+["\']',
                'message': 'ç¡¬ç¼–ç å¯†ç ',
                'severity': 'error',
                'suggestion': 'ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶å­˜å‚¨æ•æ„Ÿä¿¡æ¯'
            },
            'hardcoded_api_key': {
                'pattern': r'api_key\s*=\s*["\'][^"\']+["\']',
                'message': 'ç¡¬ç¼–ç APIå¯†é’¥',
                'severity': 'error',
                'suggestion': 'ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨APIå¯†é’¥'
            },
            'hardcoded_secret': {
                'pattern': r'secret\s*=\s*["\'][^"\']+["\']',
                'message': 'ç¡¬ç¼–ç å¯†é’¥',
                'severity': 'error',
                'suggestion': 'ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†æœåŠ¡'
            },
            'insecure_pickle': {
                'pattern': r'pickle\.loads?\s*\(',
                'message': 'ä¸å®‰å…¨çš„ååºåˆ—åŒ–ï¼šä½¿ç”¨pickle',
                'severity': 'error',
                'suggestion': 'é¿å…ååºåˆ—åŒ–ä¸å¯ä¿¡æ•°æ®ï¼Œè€ƒè™‘ä½¿ç”¨json'
            },
            'insecure_yaml': {
                'pattern': r'yaml\.load\s*\([^)]*\)(?!\s*,\s*Loader)',
                'message': 'ä¸å®‰å…¨çš„YAMLåŠ è½½',
                'severity': 'error',
                'suggestion': 'ä½¿ç”¨yaml.safe_loadæˆ–æŒ‡å®šLoader'
            },
            'path_traversal': {
                'pattern': r'\.\.\/',
                'message': 'è·¯å¾„éå†é£é™©ï¼šåŒ…å«../',
                'severity': 'warning',
                'suggestion': 'éªŒè¯å’Œæ¸…ç†æ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨os.path.realpath'
            },
        }
    
    def _init_performance_rules(self) -> Dict:
        """åˆå§‹åŒ–æ€§èƒ½è§„åˆ™"""
        return {
            'inefficient_range_len': {
                'pattern': r'for\s+\w+\s+in\s+range\s*\(\s*len\s*\(',
                'message': 'ä½æ•ˆå¾ªç¯ï¼šä½¿ç”¨range(len())è€Œä¸æ˜¯ç›´æ¥è¿­ä»£',
                'severity': 'warning',
                'suggestion': 'ä½¿ç”¨enumerate()æˆ–ç›´æ¥è¿­ä»£åºåˆ—'
            },
            'string_concat_loop': {
                'pattern': r'\+=\s*["\']',
                'message': 'å­—ç¬¦ä¸²æ‹¼æ¥ï¼šå¯èƒ½åœ¨å¾ªç¯ä¸­ä½¿ç”¨+=æ‹¼æ¥å­—ç¬¦ä¸²',
                'severity': 'warning',
                'suggestion': 'ä½¿ç”¨åˆ—è¡¨æ”¶é›†å­—ç¬¦ä¸²ï¼Œæœ€åç”¨joinè¿æ¥'
            },
            'global_usage': {
                'pattern': r'^\s*global\s+',
                'message': 'ä½¿ç”¨globalå…³é”®å­—',
                'severity': 'info',
                'suggestion': 'è€ƒè™‘ä½¿ç”¨ç±»æˆ–é—­åŒ…æ¥ç®¡ç†çŠ¶æ€'
            },
            'repeated_attribute': {
                'pattern': r'(\w+\.\w+)\s*[^=].*\1',
                'message': 'é‡å¤å±æ€§è®¿é—®',
                'severity': 'info',
                'suggestion': 'å°†é‡å¤è®¿é—®çš„å±æ€§ç¼“å­˜åˆ°å±€éƒ¨å˜é‡'
            },
            'list_append_loop': {
                'pattern': r'\.append\s*\([^)]+\)\s*$',
                'message': 'å¾ªç¯ä¸­ä½¿ç”¨append',
                'severity': 'info',
                'suggestion': 'è€ƒè™‘ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼æ›¿ä»£å¾ªç¯append'
            },
        }
    
    def _init_style_rules(self) -> Dict:
        """åˆå§‹åŒ–é£æ ¼è§„åˆ™"""
        return {
            'multiple_statements': {
                'pattern': r';\s*\w+',
                'message': 'åŒä¸€è¡Œæœ‰å¤šæ¡è¯­å¥',
                'severity': 'info',
                'suggestion': 'æ¯è¡Œåªå†™ä¸€æ¡è¯­å¥'
            },
            'comparison_with_singleton': {
                'pattern': r'==\s*(True|False|None)|(\bTrue\b|\bFalse\b|\bNone\b)\s*==',
                'message': 'ä¸å•ä¾‹å€¼ä½¿ç”¨==æ¯”è¾ƒ',
                'severity': 'info',
                'suggestion': 'ä½¿ç”¨ is æˆ– is not ä¸ True/False/None æ¯”è¾ƒ'
            },
            'wildcard_import': {
                'pattern': r'from\s+\w+\s+import\s+\*',
                'message': 'ä½¿ç”¨é€šé…ç¬¦å¯¼å…¥',
                'severity': 'warning',
                'suggestion': 'æ˜ç¡®å¯¼å…¥éœ€è¦çš„åç§°'
            },
            'bare_except': {
                'pattern': r'except\s*:',
                'message': 'ä½¿ç”¨è£¸except',
                'severity': 'warning',
                'suggestion': 'æ˜ç¡®æŒ‡å®šè¦æ•è·çš„å¼‚å¸¸ç±»å‹'
            },
        }
