# Task04 å­¦ä¹ ç¬”è®° - ç¬¬ä¹ç« :ä¸Šä¸‹æ–‡å·¥ç¨‹

**å­¦ä¹ æ—¥æœŸ**: 2024-12-22  
**å­¦ä¹ è€…**: Franke Chen

---

## ğŸ“š ç¬¬ä¸€éƒ¨åˆ†:ä¸Šä¸‹æ–‡å·¥ç¨‹æ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯ä¸Šä¸‹æ–‡å·¥ç¨‹?

**å®šä¹‰**:
ä¸Šä¸‹æ–‡å·¥ç¨‹(Context Engineering)æ˜¯æŒ‡åœ¨ä¸å¤§è¯­è¨€æ¨¡å‹(LLM)äº¤äº’æ—¶,æœ‰ç­–ç•¥åœ°æ„å»ºã€ç®¡ç†å’Œä¼˜åŒ–è¾“å…¥ä¸Šä¸‹æ–‡çš„æŠ€æœ¯å’Œæ–¹æ³•,ä»¥æé«˜æ¨¡å‹è¾“å‡ºè´¨é‡ã€é™ä½æˆæœ¬å¹¶æ»¡è¶³Tokené™åˆ¶ã€‚

**æ ¸å¿ƒç›®æ ‡**:
1. **è´¨é‡ä¼˜åŒ–**: æä¾›æœ€ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
2. **æˆæœ¬æ§åˆ¶**: åœ¨Tokené™åˆ¶å†…ä¼ é€’æœ€å¤šæœ‰æ•ˆä¿¡æ¯
3. **æ€§èƒ½æå‡**: å‡å°‘ä¸å¿…è¦çš„Tokenæ¶ˆè€—
4. **æ•ˆæœä¿è¯**: ç¡®ä¿æ¨¡å‹è·å¾—è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡

### 1.2 ä¸Šä¸‹æ–‡å·¥ç¨‹ vs Prompt Engineering

| ç»´åº¦ | Prompt Engineering | Context Engineering |
|------|-------------------|---------------------|
| **å…³æ³¨ç‚¹** | å¦‚ä½•è¡¨è¾¾æŒ‡ä»¤ | å¦‚ä½•ç»„ç»‡ä¸Šä¸‹æ–‡ |
| **ä¼˜åŒ–å¯¹è±¡** | æç¤ºè¯æœ¬èº« | æ•´ä¸ªè¾“å…¥å†…å®¹ |
| **ä¸»è¦æŠ€æœ¯** | æŒ‡ä»¤è®¾è®¡ã€Few-shot | çª—å£ç®¡ç†ã€å‹ç¼© |
| **åº”ç”¨åœºæ™¯** | å•æ¬¡è°ƒç”¨ | å¤šè½®å¯¹è¯ã€é•¿æ–‡æœ¬ |
| **Tokenå…³æ³¨** | æç¤ºè¯Token | å…¨éƒ¨è¾“å…¥Token |

**å…³ç³»**:
- Prompt Engineeringæ˜¯ä¸Šä¸‹æ–‡å·¥ç¨‹çš„ä¸€éƒ¨åˆ†
- ä¸Šä¸‹æ–‡å·¥ç¨‹åŒ…å«æ›´å¹¿æ³›çš„æŠ€æœ¯
- ä¸¤è€…ç›¸è¾…ç›¸æˆ,å…±åŒä¼˜åŒ–LLMæ€§èƒ½

### 1.3 ä¸Šä¸‹æ–‡åœ¨Agentä¸­çš„ä½œç”¨

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Agent ç³»ç»Ÿ                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  ç”¨æˆ·è¾“å…¥                                â”‚
â”‚      â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      ä¸Šä¸‹æ–‡æ„å»º(Context Build)    â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ â€¢ ç³»ç»ŸæŒ‡ä»¤(System Prompt)         â”‚  â”‚
â”‚  â”‚ â€¢ å¯¹è¯å†å²(Conversation History)  â”‚  â”‚
â”‚  â”‚ â€¢ æ£€ç´¢ä¿¡æ¯(Retrieved Info)        â”‚  â”‚
â”‚  â”‚ â€¢ å·¥å…·è¾“å‡º(Tool Outputs)          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚      â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    ä¸Šä¸‹æ–‡ä¼˜åŒ–(Context Optimize)   â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ â€¢ Tokenæ§åˆ¶                       â”‚  â”‚
â”‚  â”‚ â€¢ ç›¸å…³æ€§è¿‡æ»¤                      â”‚  â”‚
â”‚  â”‚ â€¢ ä¿¡æ¯å‹ç¼©                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚      â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         LLM å¤„ç†                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚      â†“                                  â”‚
â”‚  è¾“å‡ºç»“æœ                                â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.4 ä¸Šä¸‹æ–‡çš„ç»„æˆéƒ¨åˆ†

#### 1. ç³»ç»ŸæŒ‡ä»¤(System Prompt)
```python
system_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚
ä½ çš„å›ç­”åº”è¯¥:
- å‡†ç¡®ã€ä¸“ä¸š
- ç»“æ„æ¸…æ™°
- ç®€æ´æ˜äº†
"""
```

**ç‰¹ç‚¹**:
- å›ºå®šä¸å˜
- å®šä¹‰Agentè§’è‰²å’Œè¡Œä¸º
- Tokenæ¶ˆè€—ç›¸å¯¹å›ºå®š

#### 2. å¯¹è¯å†å²(Conversation History)
```python
history = [
    {"role": "user", "content": "ä½ å¥½"},
    {"role": "assistant", "content": "ä½ å¥½!æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„?"},
    {"role": "user", "content": "å‘Šè¯‰æˆ‘å…³äºPythonçš„ä¿¡æ¯"},
    # ...æ›´å¤šå†å²æ¶ˆæ¯
]
```

**ç‰¹ç‚¹**:
- åŠ¨æ€å¢é•¿
- ä¿æŒå¯¹è¯è¿è´¯æ€§
- æ˜¯ä¸»è¦çš„Tokenæ¶ˆè€—æº

#### 3. æ£€ç´¢ä¿¡æ¯(Retrieved Information)
```python
retrieved_info = """
ç›¸å…³æ–‡æ¡£1: Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€...
ç›¸å…³æ–‡æ¡£2: Pythonçš„ç‰¹ç‚¹åŒ…æ‹¬...
ç›¸å…³æ–‡æ¡£3: Pythonå¸¸ç”¨äº...
"""
```

**ç‰¹ç‚¹**:
- æ¥è‡ªRAGç³»ç»Ÿ
- æä¾›å¤–éƒ¨çŸ¥è¯†
- éœ€è¦ç›¸å…³æ€§è¿‡æ»¤

#### 4. å·¥å…·è¾“å‡º(Tool Outputs)
```python
tool_outputs = [
    "æœç´¢ç»“æœ: ...",
    "å¤©æ°”ä¿¡æ¯: åŒ—äº¬ä»Šå¤©æ™´å¤©,20Â°C",
    "è®¡ç®—ç»“æœ: 1234 + 5678 = 6912"
]
```

**ç‰¹ç‚¹**:
- åŠ¨æ€ç”Ÿæˆ
- ä»»åŠ¡ç›¸å…³
- éœ€è¦æ ¼å¼åŒ–

### 1.5 ä¸Šä¸‹æ–‡å·¥ç¨‹çš„æŒ‘æˆ˜

#### æŒ‘æˆ˜1: Tokené™åˆ¶
```python
# ä¸åŒæ¨¡å‹çš„Tokené™åˆ¶
model_limits = {
    "gpt-3.5-turbo": 4096,
    "gpt-4": 8192,
    "gpt-4-turbo": 128000,
    "claude-3": 200000,
}
```

**é—®é¢˜**:
- ä¸Šä¸‹æ–‡å¤ªé•¿ä¼šè¶…å‡ºé™åˆ¶
- éœ€è¦æ™ºèƒ½æˆªæ–­æˆ–å‹ç¼©
- ä¸åŒæ¨¡å‹é™åˆ¶ä¸åŒ

**è§£å†³æ€è·¯**:
- çª—å£ç®¡ç†
- ä¸Šä¸‹æ–‡å‹ç¼©
- åŠ¨æ€é€‰æ‹©

#### æŒ‘æˆ˜2: ä¿¡æ¯è¿‡è½½
```python
# ä¿¡æ¯è¿‡å¤šçš„é—®é¢˜
too_much_info = """
- 100è½®å¯¹è¯å†å²
- 50ä¸ªæ£€ç´¢ç»“æœ
- 20ä¸ªå·¥å…·è¾“å‡º
- å„ç§ç³»ç»ŸæŒ‡ä»¤
â†’ LLMå¤„ç†æ•ˆç‡ä¸‹é™
â†’ å…³é”®ä¿¡æ¯è¢«æ·¹æ²¡
â†’ æˆæœ¬æ˜¾è‘—å¢åŠ 
"""
```

**é—®é¢˜**:
- ä¿¡æ¯å¤ªå¤š,LLMéš¾ä»¥èšç„¦
- "Lost in the Middle"ç°è±¡
- å“åº”è´¨é‡ä¸‹é™

**è§£å†³æ€è·¯**:
- ç›¸å…³æ€§æ’åº
- ä¿¡æ¯è¿‡æ»¤
- åˆ†å±‚ç®¡ç†

#### æŒ‘æˆ˜3: ç›¸å…³æ€§åˆ¤æ–­
```python
# å¦‚ä½•åˆ¤æ–­å“ªäº›å†å²æ˜¯ç›¸å…³çš„?
query = "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·?"

# ç›¸å…³å†å²
relevant = [
    "æˆ‘åœ¨åŒ—äº¬",  # ç›¸å…³!
    "å¸®æˆ‘æŸ¥å¤©æ°”",  # ç›¸å…³!
]

# ä¸ç›¸å…³å†å²
irrelevant = [
    "1+1ç­‰äºå‡ ?",  # ä¸ç›¸å…³
    "è®²ä¸ªç¬‘è¯",  # ä¸ç›¸å…³
]
```

**é—®é¢˜**:
- éš¾ä»¥è‡ªåŠ¨åˆ¤æ–­ç›¸å…³æ€§
- éœ€è¦è¯­ä¹‰ç†è§£
- è®¡ç®—æˆæœ¬

**è§£å†³æ€è·¯**:
- å‘é‡ç›¸ä¼¼åº¦
- LLMè¾…åŠ©åˆ¤æ–­
- å¯å‘å¼è§„åˆ™

#### æŒ‘æˆ˜4: æˆæœ¬æ§åˆ¶
```python
# Tokenæˆæœ¬è®¡ç®—
def calculate_cost(tokens, model="gpt-4"):
    prices = {
        "gpt-3.5-turbo": {"input": 0.0015/1000, "output": 0.002/1000},
        "gpt-4": {"input": 0.03/1000, "output": 0.06/1000},
    }
    
    # å‡è®¾è¾“å…¥è¾“å‡ºæ¯”ä¾‹1:1
    cost = tokens * (prices[model]["input"] + prices[model]["output"]) / 2
    return cost

# 10000 tokensçš„æˆæœ¬
print(calculate_cost(10000, "gpt-4"))  # $0.45
```

**é—®é¢˜**:
- Tokenè¶Šå¤š,æˆæœ¬è¶Šé«˜
- é•¿å¯¹è¯æˆæœ¬ç´¯ç§¯
- éœ€è¦åœ¨è´¨é‡å’Œæˆæœ¬é—´å¹³è¡¡

**è§£å†³æ€è·¯**:
- Tokené¢„ç®—ç®¡ç†
- å‹ç¼©æŠ€æœ¯
- æ¨¡å‹é€‰æ‹©

---

## ğŸ“š ç¬¬äºŒéƒ¨åˆ†:ä¸Šä¸‹æ–‡çª—å£ç®¡ç†

### 2.1 å›ºå®šçª—å£ç­–ç•¥

#### ç­–ç•¥1: æ»‘åŠ¨çª—å£(Sliding Window)

**åŸç†**:
```python
# ä¿æŒå›ºå®šæ•°é‡çš„æ¶ˆæ¯
max_messages = 10

history = []
for message in all_messages:
    history.append(message)
    if len(history) > max_messages:
        history.pop(0)  # ç§»é™¤æœ€æ—©çš„æ¶ˆæ¯
```

**å¯è§†åŒ–**:
```
åˆå§‹çŠ¶æ€: []
æ·»åŠ M1:   [M1]
æ·»åŠ M2:   [M1, M2]
...
æ·»åŠ M10:  [M1, M2, ..., M10]
æ·»åŠ M11:  [M2, M3, ..., M11]  â† M1è¢«ç§»é™¤
æ·»åŠ M12:  [M3, M4, ..., M12]  â† M2è¢«ç§»é™¤
```

**ä¼˜ç‚¹**:
- âœ… å®ç°ç®€å•
- âœ… Tokenæ•°é‡å¯æ§
- âœ… è®¡ç®—æ•ˆç‡é«˜

**ç¼ºç‚¹**:
- âŒ å¯èƒ½ä¸¢å¤±é‡è¦ä¿¡æ¯
- âŒ æ— æ³•å¤„ç†é•¿æœŸä¾èµ–
- âŒ ç¼ºä¹çµæ´»æ€§

**é€‚ç”¨åœºæ™¯**:
- ç®€å•å¯¹è¯ç³»ç»Ÿ
- Tokené™åˆ¶ä¸¥æ ¼
- å¯¹å†å²ä¾èµ–ä¸å¼º

#### ç­–ç•¥2: å›ºå®šTokençª—å£

**åŸç†**:
```python
def keep_within_token_limit(messages, max_tokens=2000):
    """ä¿æŒTokenæ•°é‡åœ¨é™åˆ¶å†…"""
    result = []
    total_tokens = 0
    
    # ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹
    for msg in reversed(messages):
        msg_tokens = count_tokens(msg["content"])
        if total_tokens + msg_tokens <= max_tokens:
            result.insert(0, msg)
            total_tokens += msg_tokens
        else:
            break
    
    return result
```

**ä¼˜ç‚¹**:
- âœ… Tokenæ§åˆ¶ç²¾ç¡®
- âœ… åˆ©ç”¨ç‡é«˜

**ç¼ºç‚¹**:
- âŒ éœ€è¦Tokenè®¡æ•°å·¥å…·
- âŒ è®¡ç®—å¼€é”€è¾ƒå¤§

#### ç­–ç•¥3: æˆªæ–­ç­–ç•¥

**å¤´éƒ¨æˆªæ–­**:
```python
# ä¿ç•™æœ€æ–°çš„Næ¡æ¶ˆæ¯
recent_history = messages[-10:]
```

**å°¾éƒ¨æˆªæ–­**:
```python
# ä¿ç•™æœ€æ—©çš„Næ¡æ¶ˆæ¯(ç½•è§)
early_history = messages[:5]
```

**ä¸­é—´æˆªæ–­**:
```python
# ä¿ç•™å¼€å¤´å’Œç»“å°¾,ç§»é™¤ä¸­é—´
context = messages[:3] + ["..."] + messages[-5:]
```

### 2.2 åŠ¨æ€çª—å£ç­–ç•¥

#### ç­–ç•¥1: åŸºäºé‡è¦æ€§

**åŸç†**:
```python
def score_importance(message):
    """è¯„ä¼°æ¶ˆæ¯é‡è¦æ€§"""
    score = 0
    
    # è§„åˆ™1: ç”¨æˆ·æ¶ˆæ¯æ›´é‡è¦
    if message["role"] == "user":
        score += 5
    
    # è§„åˆ™2: åŒ…å«å…³é”®è¯
    keywords = ["é‡è¦", "å¿…é¡»", "å…³é”®"]
    if any(kw in message["content"] for kw in keywords):
        score += 3
    
    # è§„åˆ™3: é•¿æ¶ˆæ¯å¯èƒ½æ›´é‡è¦
    if len(message["content"]) > 100:
        score += 2
    
    return score

def keep_important_messages(messages, max_count=10):
    """ä¿ç•™æœ€é‡è¦çš„æ¶ˆæ¯"""
    # æ·»åŠ é‡è¦æ€§åˆ†æ•°
    scored = [(msg, score_importance(msg)) for msg in messages]
    
    # æŒ‰é‡è¦æ€§æ’åº
    scored.sort(key=lambda x: x[1], reverse=True)
    
    # ä¿ç•™top-k
    important = [msg for msg, _ in scored[:max_count]]
    
    return important
```

**ä¼˜ç‚¹**:
- âœ… ä¿ç•™å…³é”®ä¿¡æ¯
- âœ… æ›´æ™ºèƒ½çš„é€‰æ‹©

**ç¼ºç‚¹**:
- âŒ é‡è¦æ€§åˆ¤æ–­å›°éš¾
- âŒ å¯èƒ½æ‰“ä¹±æ—¶é—´é¡ºåº

#### ç­–ç•¥2: åŸºäºç›¸å…³æ€§

**åŸç†**:
```python
from sentence_transformers import SentenceTransformer
import numpy as np

model = SentenceTransformer('all-MiniLM-L6-v2')

def filter_relevant_messages(messages, current_query, top_k=5):
    """åŸºäºè¯­ä¹‰ç›¸å…³æ€§è¿‡æ»¤æ¶ˆæ¯"""
    
    # è·å–å½“å‰æŸ¥è¯¢çš„å‘é‡
    query_embedding = model.encode(current_query)
    
    # è®¡ç®—æ¯æ¡æ¶ˆæ¯çš„ç›¸å…³æ€§
    scored = []
    for msg in messages:
        msg_embedding = model.encode(msg["content"])
        similarity = np.dot(query_embedding, msg_embedding)
        scored.append((msg, similarity))
    
    # æŒ‰ç›¸å…³æ€§æ’åº
    scored.sort(key=lambda x: x[1], reverse=True)
    
    # è¿”å›æœ€ç›¸å…³çš„æ¶ˆæ¯
    return [msg for msg, _ in scored[:top_k]]
```

**ä¼˜ç‚¹**:
- âœ… è¯­ä¹‰çº§åˆ«åŒ¹é…
- âœ… é«˜åº¦ç›¸å…³

**ç¼ºç‚¹**:
- âŒ è®¡ç®—å¼€é”€å¤§
- âŒ éœ€è¦Embeddingæ¨¡å‹

#### ç­–ç•¥3: åŸºäºæ—¶é—´è¡°å‡

**åŸç†**:
```python
import time

def time_weighted_filter(messages, current_time, decay_factor=0.9):
    """åŸºäºæ—¶é—´è¡°å‡çš„æ¶ˆæ¯è¿‡æ»¤"""
    
    scored = []
    for msg in messages:
        # è®¡ç®—æ—¶é—´å·®(å°æ—¶)
        time_diff = (current_time - msg["timestamp"]) / 3600
        
        # æ—¶é—´è¡°å‡å› å­
        time_weight = decay_factor ** time_diff
        
        # åŸºç¡€é‡è¦æ€§
        base_score = score_importance(msg)
        
        # æœ€ç»ˆå¾—åˆ†
        final_score = base_score * time_weight
        
        scored.append((msg, final_score))
    
    scored.sort(key=lambda x: x[1], reverse=True)
    return [msg for msg, _ in scored[:10]]
```

**å…¬å¼**:
```
score(t) = base_score Ã— decay_factor^(time_diff)

ä¾‹å¦‚:
- 1å°æ—¶å‰çš„æ¶ˆæ¯: score Ã— 0.9^1 = score Ã— 0.9
- 2å°æ—¶å‰çš„æ¶ˆæ¯: score Ã— 0.9^2 = score Ã— 0.81
- 10å°æ—¶å‰çš„æ¶ˆæ¯: score Ã— 0.9^10 â‰ˆ score Ã— 0.35
```

**ä¼˜ç‚¹**:
- âœ… è‡ªç„¶ç¬¦åˆäººç±»è®°å¿†
- âœ… æ¸è¿›å¼é—å¿˜

**ç¼ºç‚¹**:
- âŒ éœ€è¦æ—¶é—´æˆ³
- âŒ å¯èƒ½ä¸¢å¤±æ—§ä½†é‡è¦çš„ä¿¡æ¯

### 2.3 æ··åˆç­–ç•¥

**åŸç†**: ç»“åˆå¤šç§ç­–ç•¥çš„ä¼˜ç‚¹

```python
class HybridContextManager:
    """æ··åˆä¸Šä¸‹æ–‡ç®¡ç†ç­–ç•¥"""
    
    def __init__(self, max_messages=20, max_tokens=4000):
        self.max_messages = max_messages
        self.max_tokens = max_tokens
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
    
    def manage_context(self, messages, current_query):
        """æ··åˆç­–ç•¥ç®¡ç†ä¸Šä¸‹æ–‡"""
        
        # æ­¥éª¤1: ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘3æ¡
        system_msgs = [m for m in messages if m["role"] == "system"]
        recent_msgs = messages[-3:]
        must_keep = system_msgs + recent_msgs
        
        # æ­¥éª¤2: ä»å‰©ä½™æ¶ˆæ¯ä¸­æŒ‰ç›¸å…³æ€§é€‰æ‹©
        remaining = [m for m in messages if m not in must_keep]
        relevant = self.filter_by_relevance(remaining, current_query, top_k=10)
        
        # æ­¥éª¤3: åˆå¹¶å¹¶æŒ‰Tokené™åˆ¶
        combined = must_keep + relevant
        final = self.keep_within_tokens(combined, self.max_tokens)
        
        return final
    
    def filter_by_relevance(self, messages, query, top_k):
        """åŸºäºç›¸å…³æ€§è¿‡æ»¤"""
        # (å®ç°å¦‚å‰æ‰€è¿°)
        pass
    
    def keep_within_tokens(self, messages, max_tokens):
        """Tokené™åˆ¶"""
        # (å®ç°å¦‚å‰æ‰€è¿°)
        pass
```

**ä¼˜ç‚¹**:
- âœ… ç»¼åˆå¤šç§ç­–ç•¥ä¼˜ç‚¹
- âœ… çµæ´»æ€§é«˜
- âœ… æ•ˆæœå¥½

**ç¼ºç‚¹**:
- âŒ å®ç°å¤æ‚
- âŒ è®¡ç®—å¼€é”€å¤§

---

## ğŸ“š ç¬¬ä¸‰éƒ¨åˆ†:ä¸Šä¸‹æ–‡å‹ç¼©æŠ€æœ¯

### 3.1 æ€»ç»“å‹ç¼©(Summarization)

#### åŸç†

ä½¿ç”¨LLMå¯¹é•¿æ–‡æœ¬è¿›è¡Œæ€»ç»“,ä¿ç•™å…³é”®ä¿¡æ¯,å‡å°‘Tokenæ•°é‡ã€‚

#### å®ç°

```python
def summarize_conversation(messages, llm_client):
    """æ€»ç»“å¯¹è¯å†å²"""
    
    # å°†æ¶ˆæ¯æ ¼å¼åŒ–
    conversation_text = ""
    for msg in messages:
        conversation_text += f"{msg['role']}: {msg['content']}\n"
    
    # æ„å»ºæ€»ç»“æç¤º
    summary_prompt = f"""
è¯·æ€»ç»“ä»¥ä¸‹å¯¹è¯çš„è¦ç‚¹:

{conversation_text}

æ€»ç»“è¦æ±‚:
1. æå–å…³é”®ä¿¡æ¯
2. ä¿æŒæ—¶é—´é¡ºåº
3. ä¸è¶…è¿‡200å­—
"""
    
    # è°ƒç”¨LLMæ€»ç»“
    summary = llm_client.chat([
        {"role": "user", "content": summary_prompt}
    ])
    
    return summary
```

#### æ¸è¿›å¼æ€»ç»“

```python
class ProgressiveSummarizer:
    """æ¸è¿›å¼æ€»ç»“å™¨"""
    
    def __init__(self, llm_client, chunk_size=10):
        self.llm_client = llm_client
        self.chunk_size = chunk_size
        self.summaries = []
    
    def add_messages(self, messages):
        """æ·»åŠ æ¶ˆæ¯"""
        if len(messages) >= self.chunk_size:
            # æ€»ç»“è¿™æ‰¹æ¶ˆæ¯
            summary = self.summarize(messages)
            self.summaries.append(summary)
            return []  # æ¸…ç©º
        return messages
    
    def get_context(self):
        """è·å–å‹ç¼©åçš„ä¸Šä¸‹æ–‡"""
        # è¿”å›æ‰€æœ‰æ€»ç»“ + å½“å‰æœªæ€»ç»“çš„æ¶ˆæ¯
        return "\n".join(self.summaries)
```

#### ä¼˜ç¼ºç‚¹

**ä¼˜ç‚¹**:
- âœ… å‹ç¼©ç‡é«˜(å¯è¾¾10:1)
- âœ… ä¿ç•™å…³é”®ä¿¡æ¯
- âœ… å¯è¯»æ€§å¥½

**ç¼ºç‚¹**:
- âŒ éœ€è¦é¢å¤–LLMè°ƒç”¨(æˆæœ¬)
- âŒ å¯èƒ½ä¸¢å¤±ç»†èŠ‚
- âŒ æœ‰å»¶è¿Ÿ

### 3.2 å‘é‡å‹ç¼©(Vector Compression)

#### åŸç†

å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º,å­˜å‚¨å‘é‡è€ŒéåŸå§‹æ–‡æœ¬,éœ€è¦æ—¶é‡å»ºæˆ–æ£€ç´¢ã€‚

#### å®ç°

```python
from sentence_transformers import SentenceTransformer
import numpy as np

class VectorMemory:
    """åŸºäºå‘é‡çš„è®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self):
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        self.vectors = []
        self.metadata = []
    
    def store(self, text, meta=None):
        """å­˜å‚¨æ–‡æœ¬çš„å‘é‡è¡¨ç¤º"""
        vector = self.model.encode(text)
        self.vectors.append(vector)
        self.metadata.append(meta or {})
    
    def retrieve(self, query, top_k=3):
        """æ£€ç´¢æœ€ç›¸å…³çš„è®°å¿†"""
        query_vec = self.model.encode(query)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = [
            np.dot(query_vec, vec) 
            for vec in self.vectors
        ]
        
        # è·å–top-kç´¢å¼•
        top_indices = np.argsort(similarities)[-top_k:]
        
        # è¿”å›å…ƒæ•°æ®
        return [self.metadata[i] for i in top_indices]
```

#### ä¼˜ç¼ºç‚¹

**ä¼˜ç‚¹**:
- âœ… å­˜å‚¨ç©ºé—´å°
- âœ… æ£€ç´¢é«˜æ•ˆ
- âœ… è¯­ä¹‰ä¿ç•™

**ç¼ºç‚¹**:
- âŒ æ— æ³•å®Œå…¨é‡å»ºåŸæ–‡
- âŒ éœ€è¦Embeddingæ¨¡å‹
- âŒ ä»…é€‚åˆæ£€ç´¢åœºæ™¯

### 3.3 æ··åˆå‹ç¼©

#### ç­–ç•¥: å…³é”®ä¿¡æ¯ä¿ç•™ + å…¶ä½™æ€»ç»“

```python
class HybridCompressor:
    """æ··åˆå‹ç¼©å™¨"""
    
    def __init__(self, llm_client):
        self.llm_client = llm_client
    
    def compress(self, messages, keep_recent=3):
        """æ··åˆå‹ç¼©ç­–ç•¥"""
        
        # 1. ä¿ç•™æœ€è¿‘Næ¡æ¶ˆæ¯(å®Œæ•´)
        recent = messages[-keep_recent:]
        
        # 2. æ€»ç»“æ›´æ—©çš„æ¶ˆæ¯
        old_messages = messages[:-keep_recent]
        if old_messages:
            summary = self.summarize(old_messages)
            compressed = [
                {"role": "system", "content": f"å†å²å¯¹è¯æ€»ç»“:\n{summary}"}
            ]
        else:
            compressed = []
        
        # 3. åˆå¹¶
        return compressed + recent
    
    def summarize(self, messages):
        """æ€»ç»“æ¶ˆæ¯"""
        # (å®ç°å¦‚å‰æ‰€è¿°)
        pass
```

---

## ğŸ“š ç¬¬å››éƒ¨åˆ†:å®è·µä»£ç æ¡†æ¶

### 4.1 ContextManagerå®ç°

```python
# è¯¦è§ ä»£ç å®è·µ/context_manager.py
```

### 4.2 ContextOptimizerå®ç°

```python
# è¯¦è§ ä»£ç å®è·µ/context_optimizer.py
```

### 4.3 ContextAwareAgentå®ç°

```python
# è¯¦è§ ä»£ç å®è·µ/context_aware_agent.py
```

---

## ğŸ’¡ å…³é”®è¦ç‚¹æ€»ç»“

### æ ¸å¿ƒæ¦‚å¿µ
1. ä¸Šä¸‹æ–‡å·¥ç¨‹æ˜¯ä¼˜åŒ–LLMè¾“å…¥çš„ç³»ç»Ÿæ€§æ–¹æ³•
2. éœ€è¦å¹³è¡¡è´¨é‡ã€æˆæœ¬å’Œæ•ˆç‡
3. ä¸åŒåœºæ™¯éœ€è¦ä¸åŒç­–ç•¥

### æŠ€æœ¯è¦ç‚¹
1. **çª—å£ç®¡ç†**: æ§åˆ¶ä¸Šä¸‹æ–‡å¤§å°
2. **å‹ç¼©æŠ€æœ¯**: å‡å°‘Tokenæ¶ˆè€—
3. **ç›¸å…³æ€§è¿‡æ»¤**: ä¿ç•™é‡è¦ä¿¡æ¯
4. **åŠ¨æ€è°ƒæ•´**: æ ¹æ®ä»»åŠ¡ä¼˜åŒ–

### æœ€ä½³å®è·µ
1. ä¼˜å…ˆä½¿ç”¨ç®€å•ç­–ç•¥(æ»‘åŠ¨çª—å£)
2. æ ¹æ®éœ€æ±‚é€æ­¥å¼•å…¥é«˜çº§æŠ€æœ¯
3. ç›‘æ§Tokenæ¶ˆè€—å’Œæˆæœ¬
4. A/Bæµ‹è¯•ä¸åŒç­–ç•¥æ•ˆæœ

---

**å­¦ä¹ æ—¶é—´**: [å¾…å¡«å†™]  
**å®Œæˆåº¦**: è¿›è¡Œä¸­  
**ä¸‹ä¸€æ­¥**: å¼€å§‹ä»£ç å®è·µ
