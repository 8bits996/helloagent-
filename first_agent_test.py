"""
ç¬¬ä¸€ç« èŠ‚ç¤ºä¾‹ - FirstAgentTest
é€‚é…ç‰ˆæœ¬ - ä½¿ç”¨æˆ‘ä»¬çš„ .env é…ç½®
"""
import requests
import json
import os
import re
from openai import OpenAI
from tavily import TavilyClient
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ä» .env åŠ è½½é…ç½®
API_KEY = os.getenv("LLM_API_KEY")
BASE_URL = os.getenv("LLM_BASE_URL")
MODEL_ID = os.getenv("LLM_MODEL_ID")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")

os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY

# ç³»ç»Ÿæç¤ºè¯
AGENT_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·çš„è¯·æ±‚ï¼Œå¹¶ä½¿ç”¨å¯ç”¨å·¥å…·ä¸€æ­¥æ­¥åœ°è§£å†³é—®é¢˜ã€‚

# å¯ç”¨å·¥å…·:
- `get_weather(city: str)`: æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”ã€‚
- `get_attraction(city: str, weather: str)`: æ ¹æ®åŸå¸‚å’Œå¤©æ°”æœç´¢æ¨èçš„æ—…æ¸¸æ™¯ç‚¹ã€‚

# è¡ŒåŠ¨æ ¼å¼:
ä½ çš„å›ç­”å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼ã€‚é¦–å…ˆæ˜¯ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œç„¶åæ˜¯ä½ è¦æ‰§è¡Œçš„å…·ä½“è¡ŒåŠ¨ï¼Œæ¯æ¬¡å›å¤åªè¾“å‡ºä¸€å¯¹Thought-Actionï¼š
Thought: [è¿™é‡Œæ˜¯ä½ çš„æ€è€ƒè¿‡ç¨‹å’Œä¸‹ä¸€æ­¥è®¡åˆ’]
Action: [è¿™é‡Œæ˜¯ä½ è¦è°ƒç”¨çš„å·¥å…·ï¼Œæ ¼å¼ä¸º function_name(arg_name="arg_value")]

# ä»»åŠ¡å®Œæˆ:
å½“ä½ æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œèƒ½å¤Ÿå›ç­”ç”¨æˆ·çš„æœ€ç»ˆé—®é¢˜æ—¶ï¼Œä½ å¿…é¡»åœ¨`Action:`å­—æ®µåä½¿ç”¨ `finish(answer="...")` æ¥è¾“å‡ºæœ€ç»ˆç­”æ¡ˆã€‚

è¯·å¼€å§‹å§ï¼
"""

# ========================================
# å·¥å…·å‡½æ•°å®šä¹‰
# ========================================
def get_weather(city: str) -> str:
    """
    é€šè¿‡è°ƒç”¨ wttr.in API æŸ¥è¯¢çœŸå®çš„å¤©æ°”ä¿¡æ¯ã€‚
    """
    url = f"https://wttr.in/{city}?format=j1"
    
    try:
        response = requests.get(url)
        response.raise_for_status() 
        data = response.json()
        
        current_condition = data['current_condition'][0]
        weather_desc = current_condition['weatherDesc'][0]['value']
        temp_c = current_condition['temp_C']
        
        return f"{city}å½“å‰å¤©æ°”ï¼š{weather_desc}ï¼Œæ°”æ¸©{temp_c}æ‘„æ°åº¦"
        
    except requests.exceptions.RequestException as e:
        return f"é”™è¯¯ï¼šæŸ¥è¯¢å¤©æ°”æ—¶é‡åˆ°ç½‘ç»œé—®é¢˜ - {e}"
    except (KeyError, IndexError) as e:
        return f"é”™è¯¯ï¼šè§£æå¤©æ°”æ•°æ®å¤±è´¥ï¼Œå¯èƒ½æ˜¯åŸå¸‚åç§°æ— æ•ˆ - {e}"

def get_attraction(city: str, weather: str) -> str:
    """
    æ ¹æ®åŸå¸‚å’Œå¤©æ°”ï¼Œä½¿ç”¨Tavily Search APIæœç´¢å¹¶è¿”å›ä¼˜åŒ–åçš„æ™¯ç‚¹æ¨èã€‚
    """
    api_key = os.environ.get("TAVILY_API_KEY")

    if not api_key:
        return "é”™è¯¯ï¼šæœªé…ç½®TAVILY_API_KEYã€‚"

    tavily = TavilyClient(api_key=api_key)
    query = f"'{city}' åœ¨'{weather}'å¤©æ°”ä¸‹æœ€å€¼å¾—å»çš„æ—…æ¸¸æ™¯ç‚¹æ¨èåŠç†ç”±"
    
    try:
        response = tavily.search(query=query, search_depth="basic", include_answer=True)
        
        if response.get("answer"):
            return response["answer"]
        
        formatted_results = []
        for result in response.get("results", []):
            formatted_results.append(f"- {result['title']}: {result['content']}")
        
        if not formatted_results:
             return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„æ—…æ¸¸æ™¯ç‚¹æ¨èã€‚"

        return "æ ¹æ®æœç´¢ï¼Œä¸ºæ‚¨æ‰¾åˆ°ä»¥ä¸‹ä¿¡æ¯ï¼š\n" + "\n".join(formatted_results)

    except Exception as e:
        return f"é”™è¯¯ï¼šæ‰§è¡ŒTavilyæœç´¢æ—¶å‡ºç°é—®é¢˜ - {e}"

available_tools = {
    "get_weather": get_weather,
    "get_attraction": get_attraction,
}

print("âœ… å·¥å…·å‡½æ•°å®šä¹‰å®Œæˆ!")

# ========================================
# LLM å®¢æˆ·ç«¯
# ========================================
class OpenAICompatibleClient:
    def __init__(self, model: str, api_key: str, base_url: str):
        self.model = model
        self.client = OpenAI(api_key=api_key, base_url=base_url)

    def generate(self, prompt: str, system_prompt: str) -> str:
        print("ğŸ§  æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...")
        try:
            messages = [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': prompt}
            ]
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                stream=False
            )
            answer = response.choices[0].message.content
            print("âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸã€‚")
            return answer
        except Exception as e:
            print(f"âŒ è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return "é”™è¯¯ï¼šè°ƒç”¨è¯­è¨€æ¨¡å‹æœåŠ¡æ—¶å‡ºé”™ã€‚"

# ========================================
# æ—…è¡ŒåŠ©æ‰‹ç±»
# ========================================
class TravelAssistant:
    def __init__(self):
        self.llm = OpenAICompatibleClient(
            model=MODEL_ID,
            api_key=API_KEY,
            base_url=BASE_URL
        )
        self.prompt_history = []
    
    def reset(self):
        self.prompt_history = []
    
    def add_user_message(self, message: str):
        self.prompt_history.append(f"ç”¨æˆ·è¯·æ±‚: {message}")
    
    def add_assistant_message(self, message: str):
        self.prompt_history.append(message)
    
    def add_observation(self, observation: str):
        self.prompt_history.append(f"Observation: {observation}")

print("âœ… æ™ºèƒ½åŠ©æ‰‹ç±»å®šä¹‰å®Œæˆ!")

# ========================================
# è¾…åŠ©å‡½æ•°
# ========================================
def parse_action(action_str):
    """è§£æè¡ŒåŠ¨å­—ç¬¦ä¸²"""
    if action_str.startswith("finish"):
        match = re.search(r'finish\(answer="(.*)"\)', action_str)
        if match:
            return "finish", {"answer": match.group(1)}
        return "finish", {"answer": "ä»»åŠ¡å®Œæˆ"}
    
    tool_name_match = re.search(r"(\w+)\(", action_str)
    if not tool_name_match:
        return None, {}
    
    tool_name = tool_name_match.group(1)
    args_match = re.search(r"\((.*)\)", action_str)
    if args_match:
        args_str = args_match.group(1)
        kwargs = dict(re.findall(r'(\w+)="([^"]*)"', args_str))
    else:
        kwargs = {}
    
    return tool_name, kwargs

print("âœ… è¾…åŠ©å‡½æ•°å®šä¹‰å®Œæˆ!")

# ========================================
# ä¸»è¿è¡Œå‡½æ•°
# ========================================
def run_assistant(user_input, max_iterations=5):
    """è¿è¡Œæ—…è¡ŒåŠ©æ‰‹"""
    assistant = TravelAssistant()
    assistant.add_user_message(user_input)
    
    print(f"\n{'=' * 70}")
    print(f"ğŸ‘¤ ç”¨æˆ·è¾“å…¥: {user_input}")
    print(f"{'=' * 70}\n")
    
    for i in range(max_iterations):
        print(f"\nğŸ”„ å¾ªç¯ {i+1}/{max_iterations}")
        print("-" * 70)
        
        # æ„å»ºå®Œæ•´promptå¹¶è°ƒç”¨LLM
        full_prompt = "\n".join(assistant.prompt_history)
        llm_output = assistant.llm.generate(full_prompt, AGENT_SYSTEM_PROMPT)
        
        # æˆªæ–­å¤šä½™çš„Thought-Action
        match = re.search(r'(Thought:.*?Action:.*?)(?=\n\s*(?:Thought:|Action:|Observation:)|\Z)', llm_output, re.DOTALL)
        if match:
            truncated = match.group(1).strip()
            if truncated != llm_output.strip():
                llm_output = truncated
                print("âš ï¸  å·²æˆªæ–­å¤šä½™çš„ Thought-Action å¯¹")
        
        assistant.add_assistant_message(llm_output)
        
        print(f"\nğŸ¤– æ¨¡å‹è¾“å‡º:\n{llm_output}\n")
        
        # è§£æè¡ŒåŠ¨
        action_match = re.search(r"Action: (.*)", llm_output, re.DOTALL)
        if not action_match:
            print("âŒ è§£æé”™è¯¯ï¼šæ¨¡å‹è¾“å‡ºä¸­æœªæ‰¾åˆ° Actionã€‚")
            break
            
        action_str = action_match.group(1).strip()
        tool_name, kwargs = parse_action(action_str)
        
        # å¤„ç†å®Œæˆè¡ŒåŠ¨
        if tool_name == "finish":
            final_answer = kwargs.get("answer", "ä»»åŠ¡å®Œæˆ")
            print(f"\n{'=' * 70}")
            print(f"ğŸ‰ ä»»åŠ¡å®Œæˆ!")
            print(f"{'=' * 70}")
            print(f"\nâœ… æœ€ç»ˆç­”æ¡ˆ:\n{final_answer}\n")
            print(f"{'=' * 70}\n")
            return final_answer, assistant.prompt_history
        
        # å¤„ç†å·¥å…·è°ƒç”¨
        if tool_name in available_tools:
            print(f"ğŸ› ï¸  è°ƒç”¨å·¥å…·: {tool_name}({kwargs})")
            observation = available_tools[tool_name](**kwargs)
        else:
            observation = f"é”™è¯¯ï¼šæœªå®šä¹‰çš„å·¥å…· '{tool_name}'"
        
        print(f"\nğŸ“Š è§‚å¯Ÿç»“æœ:\n{observation}")
        print("-" * 70)
        
        assistant.add_observation(observation)
    
    timeout_answer = "æŠ±æ­‰ï¼Œç»è¿‡å¤šæ¬¡å°è¯•ä»æœªå®Œæˆæ‚¨çš„è¯·æ±‚ã€‚"
    print(f"\nâ° è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°\n")
    return timeout_answer, assistant.prompt_history

# ========================================
# æµ‹è¯•ç¤ºä¾‹
# ========================================
if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("ğŸš€ ç¬¬ä¸€ç« èŠ‚ç¤ºä¾‹ - æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹æµ‹è¯•")
    print("=" * 70)
    
    # æµ‹è¯•é—®é¢˜
    user_input = "ä½ å¥½ï¼Œè¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹ä»Šå¤©åŒ—äº¬çš„å¤©æ°”ï¼Œç„¶åæ ¹æ®å¤©æ°”æ¨èä¸€ä¸ªåˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚"
    
    # è¿è¡ŒåŠ©æ‰‹
    final_answer, history = run_assistant(user_input, max_iterations=5)
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")
