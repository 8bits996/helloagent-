"""
ä¸Šä¸‹æ–‡ä¼˜åŒ–å™¨ (Context Optimizer)

æä¾›é«˜çº§ä¸Šä¸‹æ–‡ä¼˜åŒ–åŠŸèƒ½:
1. ç›¸å…³æ€§è¿‡æ»¤ (Relevance Filtering)
2. å¯¹è¯æ€»ç»“å‹ç¼© (Summarization)
3. ä¿¡æ¯å¯†åº¦ä¼˜åŒ– (Density Optimization)
4. åŠ¨æ€ä¸Šä¸‹æ–‡æ„å»º (Dynamic Context Building)

Author: Franke Chen
Date: 2024-12-22
"""

from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import sys
import os

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„,ä»¥ä¾¿å¯¼å…¥hello_agents_llm
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from context_manager import Message, estimate_tokens


@dataclass
class OptimizationResult:
    """ä¼˜åŒ–ç»“æœ"""
    original_messages: int
    optimized_messages: int
    original_tokens: int
    optimized_tokens: int
    compression_ratio: float
    strategy_used: str
    
    def __str__(self) -> str:
        return f"""
ä¼˜åŒ–ç»“æœ:
  åŸå§‹æ¶ˆæ¯æ•°: {self.original_messages}
  ä¼˜åŒ–åæ¶ˆæ¯æ•°: {self.optimized_messages}
  åŸå§‹Tokenæ•°: {self.original_tokens}
  ä¼˜åŒ–åTokenæ•°: {self.optimized_tokens}
  å‹ç¼©ç‡: {self.compression_ratio:.1%}
  ä½¿ç”¨ç­–ç•¥: {self.strategy_used}
"""


class ContextOptimizer:
    """
    ä¸Šä¸‹æ–‡ä¼˜åŒ–å™¨
    
    æä¾›å¤šç§ä¼˜åŒ–ç­–ç•¥æ¥å‡å°‘Tokenæ¶ˆè€—å¹¶æé«˜ä¸Šä¸‹æ–‡è´¨é‡
    """
    
    def __init__(self, llm_client=None):
        """
        åˆå§‹åŒ–
        
        Args:
            llm_client: LLMå®¢æˆ·ç«¯(ç”¨äºæ€»ç»“åŠŸèƒ½,å¯é€‰)
        """
        self.llm_client = llm_client
    
    def optimize(
        self,
        messages: List[Message],
        target_tokens: int = 2000,
        strategy: str = "auto"
    ) -> tuple[List[Message], OptimizationResult]:
        """
        ä¼˜åŒ–ä¸Šä¸‹æ–‡
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            target_tokens: ç›®æ ‡Tokenæ•°
            strategy: ä¼˜åŒ–ç­–ç•¥ (auto/truncate/summarize/hybrid)
            
        Returns:
            (ä¼˜åŒ–åçš„æ¶ˆæ¯, ä¼˜åŒ–ç»“æœ)
        """
        original_tokens = sum(estimate_tokens(msg.content) for msg in messages)
        
        # å¦‚æœå·²ç»åœ¨ç›®æ ‡èŒƒå›´å†…,ä¸éœ€è¦ä¼˜åŒ–
        if original_tokens <= target_tokens:
            result = OptimizationResult(
                original_messages=len(messages),
                optimized_messages=len(messages),
                original_tokens=original_tokens,
                optimized_tokens=original_tokens,
                compression_ratio=0.0,
                strategy_used="none"
            )
            return messages, result
        
        # æ ¹æ®ç­–ç•¥é€‰æ‹©ä¼˜åŒ–æ–¹æ³•
        if strategy == "auto":
            # è‡ªåŠ¨é€‰æ‹©: Tokenè¶…å‡ºè¾ƒå¤šæ—¶ç”¨æ€»ç»“,å¦åˆ™ç”¨æˆªæ–­
            ratio = original_tokens / target_tokens
            if ratio > 2.0 and self.llm_client:
                strategy = "summarize"
            else:
                strategy = "truncate"
        
        if strategy == "truncate":
            optimized = self._truncate_optimize(messages, target_tokens)
            strategy_name = "æˆªæ–­ä¼˜åŒ–"
        elif strategy == "summarize":
            optimized = self._summarize_optimize(messages, target_tokens)
            strategy_name = "æ€»ç»“å‹ç¼©"
        elif strategy == "hybrid":
            optimized = self._hybrid_optimize(messages, target_tokens)
            strategy_name = "æ··åˆä¼˜åŒ–"
        else:
            optimized = messages
            strategy_name = "æœªçŸ¥ç­–ç•¥"
        
        optimized_tokens = sum(estimate_tokens(msg.content) for msg in optimized)
        compression_ratio = (original_tokens - optimized_tokens) / original_tokens if original_tokens > 0 else 0.0
        
        result = OptimizationResult(
            original_messages=len(messages),
            optimized_messages=len(optimized),
            original_tokens=original_tokens,
            optimized_tokens=optimized_tokens,
            compression_ratio=compression_ratio,
            strategy_used=strategy_name
        )
        
        return optimized, result
    
    def _truncate_optimize(
        self,
        messages: List[Message],
        target_tokens: int
    ) -> List[Message]:
        """
        æˆªæ–­ä¼˜åŒ–: ä¿ç•™æœ€é‡è¦çš„æ¶ˆæ¯
        
        ç­–ç•¥:
        1. ç³»ç»Ÿæ¶ˆæ¯æ€»æ˜¯ä¿ç•™
        2. æœ€è¿‘3æ¡æ¶ˆæ¯ä¿ç•™
        3. å…¶ä½™æŒ‰é‡è¦æ€§é€‰æ‹©
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            target_tokens: ç›®æ ‡Tokenæ•°
            
        Returns:
            ä¼˜åŒ–åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        # åˆ†ç¦»ç³»ç»Ÿæ¶ˆæ¯
        system_msgs = [msg for msg in messages if msg.role == "system"]
        non_system = [msg for msg in messages if msg.role != "system"]
        
        # ä¿ç•™æœ€è¿‘3æ¡
        recent = non_system[-3:] if len(non_system) >= 3 else non_system
        remaining = non_system[:-3] if len(non_system) > 3 else []
        
        # è®¡ç®—å·²ä½¿ç”¨Token
        selected = system_msgs + recent
        used_tokens = sum(estimate_tokens(msg.content) for msg in selected)
        
        # ä»å‰©ä½™æ¶ˆæ¯ä¸­æŒ‰é‡è¦æ€§é€‰æ‹©
        remaining.sort(key=lambda x: x.importance, reverse=True)
        
        for msg in remaining:
            msg_tokens = estimate_tokens(msg.content)
            if used_tokens + msg_tokens <= target_tokens:
                selected.append(msg)
                used_tokens += msg_tokens
        
        # æŒ‰æ—¶é—´æ’åº
        selected.sort(key=lambda x: x.timestamp)
        
        return selected
    
    def _summarize_optimize(
        self,
        messages: List[Message],
        target_tokens: int
    ) -> List[Message]:
        """
        æ€»ç»“å‹ç¼©: ä½¿ç”¨LLMæ€»ç»“æ—§æ¶ˆæ¯
        
        ç­–ç•¥:
        1. ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯(ä¸æ€»ç»“)
        2. æ€»ç»“æ›´æ—©çš„æ¶ˆæ¯
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            target_tokens: ç›®æ ‡Tokenæ•°
            
        Returns:
            ä¼˜åŒ–åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        if not self.llm_client:
            # å¦‚æœæ²¡æœ‰LLM,å›é€€åˆ°æˆªæ–­
            return self._truncate_optimize(messages, target_tokens)
        
        # ä¿ç•™æœ€è¿‘5æ¡æ¶ˆæ¯
        keep_recent = 5
        recent = messages[-keep_recent:] if len(messages) > keep_recent else messages
        old_messages = messages[:-keep_recent] if len(messages) > keep_recent else []
        
        if not old_messages:
            return recent
        
        # æ€»ç»“æ—§æ¶ˆæ¯
        summary = self._summarize_messages(old_messages)
        
        # åˆ›å»ºæ€»ç»“æ¶ˆæ¯
        summary_msg = Message(
            role="system",
            content=f"[å†å²å¯¹è¯æ€»ç»“]\n{summary}",
            importance=8.0
        )
        
        return [summary_msg] + recent
    
    def _summarize_messages(self, messages: List[Message]) -> str:
        """
        æ€»ç»“æ¶ˆæ¯åˆ—è¡¨
        
        Args:
            messages: è¦æ€»ç»“çš„æ¶ˆæ¯
            
        Returns:
            æ€»ç»“æ–‡æœ¬
        """
        # æ„å»ºå¯¹è¯æ–‡æœ¬
        conversation = []
        for msg in messages:
            conversation.append(f"{msg.role}: {msg.content}")
        
        conversation_text = "\n".join(conversation)
        
        # æ„å»ºæ€»ç»“æç¤º
        prompt = f"""è¯·æ€»ç»“ä»¥ä¸‹å¯¹è¯çš„è¦ç‚¹,è¦æ±‚:
1. æå–å…³é”®ä¿¡æ¯å’Œå†³ç­–
2. ä¿æŒæ—¶é—´é¡ºåº
3. ç®€æ´æ˜äº†,ä¸è¶…è¿‡150å­—

å¯¹è¯å†…å®¹:
{conversation_text}

æ€»ç»“:"""
        
        try:
            # è°ƒç”¨LLMæ€»ç»“
            summary = self.llm_client.chat([{"role": "user", "content": prompt}])
            return summary
        except Exception as e:
            # å¦‚æœæ€»ç»“å¤±è´¥,è¿”å›ç®€å•æ‘˜è¦
            return f"åŒ…å«{len(messages)}æ¡å¯¹è¯,æ¶‰åŠ:{conversation_text[:100]}..."
    
    def _hybrid_optimize(
        self,
        messages: List[Message],
        target_tokens: int
    ) -> List[Message]:
        """
        æ··åˆä¼˜åŒ–: ç»“åˆæˆªæ–­å’Œæ€»ç»“
        
        ç­–ç•¥:
        1. æœ€è¿‘çš„æ¶ˆæ¯ä¿æŒå®Œæ•´
        2. ä¸­é—´çš„æ¶ˆæ¯æ€»ç»“
        3. é‡è¦çš„æ—§æ¶ˆæ¯ä¿ç•™
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            target_tokens: ç›®æ ‡Tokenæ•°
            
        Returns:
            ä¼˜åŒ–åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        # åˆ†ç»„
        system_msgs = [msg for msg in messages if msg.role == "system"]
        non_system = [msg for msg in messages if msg.role != "system"]
        
        if len(non_system) <= 5:
            return self._truncate_optimize(messages, target_tokens)
        
        # æœ€è¿‘3æ¡å®Œæ•´ä¿ç•™
        recent = non_system[-3:]
        
        # ä¸­é—´éƒ¨åˆ†æ€»ç»“
        middle = non_system[:-3]
        if middle and self.llm_client:
            summary = self._summarize_messages(middle)
            summary_msg = Message(
                role="system",
                content=f"[å¯¹è¯å†å²]\n{summary}",
                importance=7.0
            )
            result = system_msgs + [summary_msg] + recent
        else:
            result = system_msgs + recent
        
        # æ£€æŸ¥Tokené™åˆ¶
        total_tokens = sum(estimate_tokens(msg.content) for msg in result)
        if total_tokens > target_tokens:
            # å¦‚æœè¿˜æ˜¯è¶…äº†,è¿›ä¸€æ­¥æˆªæ–­
            return self._truncate_optimize(result, target_tokens)
        
        return result
    
    def filter_by_relevance(
        self,
        messages: List[Message],
        query: str,
        top_k: int = 5,
        min_score: float = 0.1
    ) -> List[Message]:
        """
        åŸºäºç›¸å…³æ€§è¿‡æ»¤æ¶ˆæ¯
        
        ä½¿ç”¨ç®€å•çš„å…³é”®è¯åŒ¹é…è®¡ç®—ç›¸å…³æ€§
        ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: ä¿ç•™æœ€ç›¸å…³çš„Kæ¡
            min_score: æœ€ä½ç›¸å…³æ€§åˆ†æ•°
            
        Returns:
            è¿‡æ»¤åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        # æå–æŸ¥è¯¢å…³é”®è¯(æ”¯æŒä¸­æ–‡)
        query_lower = query.lower()
        query_words = query.split()  # åŒ…å«ä¸­æ–‡è¯
        
        # è®¡ç®—æ¯æ¡æ¶ˆæ¯çš„ç›¸å…³æ€§
        scored = []
        for msg in messages:
            # ç³»ç»Ÿæ¶ˆæ¯æ€»æ˜¯ä¿ç•™
            if msg.role == "system":
                scored.append((msg, 10.0))
                continue
            
            content_lower = msg.content.lower()
            
            # æ–¹æ³•1: ç›´æ¥åŒ…å«æŸ¥è¯¢è¯(é€‚åˆä¸­æ–‡)
            direct_match = sum(1 for word in query_words if word in content_lower)
            
            # æ–¹æ³•2: è¯é‡å (é€‚åˆè‹±æ–‡)
            msg_words = msg.content.split()
            msg_words_set = set(msg_words)
            query_words_set = set(query_words)
            overlap = len(query_words_set & msg_words_set)
            
            # ç»¼åˆåˆ†æ•°
            score = (direct_match * 0.7 + overlap * 0.3) / max(len(query_words), 1)
            
            scored.append((msg, score))
        
        # æŒ‰ç›¸å…³æ€§æ’åº
        scored.sort(key=lambda x: x[1], reverse=True)
        
        # é€‰æ‹©top-k(è‡³å°‘åŒ…å«ç›¸å…³æ€§>min_scoreçš„æ¶ˆæ¯)
        selected = []
        for msg, score in scored:
            if len(selected) < top_k and score >= min_score:
                selected.append(msg)
        
        # æŒ‰æ—¶é—´æ’åº
        selected.sort(key=lambda x: x.timestamp)
        
        return selected
    
    def calculate_density(self, messages: List[Message]) -> float:
        """
        è®¡ç®—ä¿¡æ¯å¯†åº¦
        
        ä¿¡æ¯å¯†åº¦ = æœ‰æ•ˆä¿¡æ¯é‡ / Tokenæ•°é‡
        è¿™é‡Œç”¨å”¯ä¸€è¯æ•°ä½œä¸ºæœ‰æ•ˆä¿¡æ¯é‡çš„è¿‘ä¼¼
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            ä¿¡æ¯å¯†åº¦åˆ†æ•°
        """
        if not messages:
            return 0.0
        
        # ç»Ÿè®¡å”¯ä¸€è¯
        all_words = set()
        total_tokens = 0
        
        for msg in messages:
            words = msg.content.split()
            all_words.update(words)
            total_tokens += estimate_tokens(msg.content)
        
        if total_tokens == 0:
            return 0.0
        
        # å¯†åº¦ = å”¯ä¸€è¯æ•° / Tokenæ•°
        density = len(all_words) / total_tokens
        
        return density


# ============= æµ‹è¯•ä»£ç  =============

def create_test_messages() -> List[Message]:
    """åˆ›å»ºæµ‹è¯•æ¶ˆæ¯"""
    messages = []
    
    # ç³»ç»Ÿæ¶ˆæ¯
    messages.append(Message(
        role="system",
        content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹,æ“…é•¿å›ç­”å„ç§é—®é¢˜ã€‚",
        importance=10.0
    ))
    
    # æ—©æœŸå¯¹è¯(ä¼šè¢«å‹ç¼©)
    messages.append(Message(
        role="user",
        content="ä½ å¥½,è¯·é—®ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·?",
        importance=3.0
    ))
    messages.append(Message(
        role="assistant",
        content="ä½ å¥½!ä»Šå¤©å¤©æ°”æ™´æœ—,æ¸©åº¦é€‚ä¸­,é€‚åˆå¤–å‡ºæ´»åŠ¨ã€‚",
        importance=3.0
    ))
    
    # ä¸­é—´å¯¹è¯
    messages.append(Message(
        role="user",
        content="èƒ½æ¨èä¸€äº›é€‚åˆç°åœ¨å»çš„æ™¯ç‚¹å—?",
        importance=5.0
    ))
    messages.append(Message(
        role="assistant",
        content="å½“ç„¶å¯ä»¥!æ ¹æ®ä»Šå¤©çš„å¥½å¤©æ°”,æˆ‘æ¨èä½ å»å…¬å›­æ•£æ­¥,æˆ–è€…å»åšç‰©é¦†å‚è§‚ã€‚è¿™ä¸¤ä¸ªåœ°æ–¹éƒ½å¾ˆé€‚åˆã€‚",
        importance=5.0
    ))
    
    # é‡è¦å¯¹è¯
    messages.append(Message(
        role="user",
        content="æˆ‘éœ€è¦é¢„è®¢æ˜å¤©çš„ç«è½¦ç¥¨,è¯·å¸®æˆ‘æŸ¥ä¸€ä¸‹åŒ—äº¬åˆ°ä¸Šæµ·çš„é«˜é“ã€‚",
        importance=9.0
    ))
    messages.append(Message(
        role="assistant",
        content="å¥½çš„,æˆ‘æ¥å¸®ä½ æŸ¥è¯¢åŒ—äº¬åˆ°ä¸Šæµ·çš„é«˜é“ç¥¨ã€‚æ˜å¤©æœ‰å¤šä¸ªç­æ¬¡,æœ€æ—©çš„æ˜¯æ—©ä¸Š6:00,æœ€æ™šçš„æ˜¯æ™šä¸Š8:00ã€‚",
        importance=9.0
    ))
    
    # æœ€è¿‘å¯¹è¯
    messages.append(Message(
        role="user",
        content="é€‰æ—©ä¸Š8ç‚¹çš„é‚£ç­å§ã€‚",
        importance=8.0
    ))
    messages.append(Message(
        role="assistant",
        content="å¥½çš„,æˆ‘å¸®ä½ é€‰æ‹©æ—©ä¸Š8:00çš„G1æ¬¡åˆ—è½¦ã€‚è¯·ç¡®è®¤æ‚¨çš„ä¸ªäººä¿¡æ¯ã€‚",
        importance=8.0
    ))
    
    return messages


def test_truncate_optimization():
    """æµ‹è¯•æˆªæ–­ä¼˜åŒ–"""
    print("=" * 50)
    print("æµ‹è¯•1: æˆªæ–­ä¼˜åŒ–")
    print("=" * 50)
    
    optimizer = ContextOptimizer()
    messages = create_test_messages()
    
    # åŸå§‹Tokenæ•°
    original_tokens = sum(estimate_tokens(msg.content) for msg in messages)
    print(f"\nåŸå§‹æ¶ˆæ¯: {len(messages)}æ¡, {original_tokens} tokens")
    
    # ä¼˜åŒ–åˆ°100 tokens
    optimized, result = optimizer.optimize(messages, target_tokens=100, strategy="truncate")
    
    print(result)
    
    print("ä¿ç•™çš„æ¶ˆæ¯:")
    for msg in optimized:
        tokens = estimate_tokens(msg.content)
        print(f"  [{msg.role}] ({tokens}t): {msg.content[:40]}...")
    
    assert result.optimized_tokens <= 100, "åº”è¯¥åœ¨Tokené™åˆ¶å†…"
    print("\nâœ… æˆªæ–­ä¼˜åŒ–æµ‹è¯•é€šè¿‡!")


def test_relevance_filtering():
    """æµ‹è¯•ç›¸å…³æ€§è¿‡æ»¤"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•2: ç›¸å…³æ€§è¿‡æ»¤")
    print("=" * 50)
    
    optimizer = ContextOptimizer()
    messages = create_test_messages()
    
    # æŸ¥è¯¢å…³äºç«è½¦ç¥¨çš„ä¿¡æ¯
    query = "ç«è½¦ç¥¨ é«˜é“ é¢„è®¢"
    
    print(f"\næŸ¥è¯¢: {query}")
    print(f"åŸå§‹æ¶ˆæ¯æ•°: {len(messages)}")
    
    filtered = optimizer.filter_by_relevance(messages, query, top_k=4, min_score=0.1)
    
    print(f"è¿‡æ»¤åæ¶ˆæ¯æ•°: {len(filtered)}")
    print("\nä¿ç•™çš„æ¶ˆæ¯:")
    for msg in filtered:
        print(f"  [{msg.role}]: {msg.content[:50]}...")
    
    # éªŒè¯ç›¸å…³æ¶ˆæ¯è¢«ä¿ç•™
    contents = [msg.content for msg in filtered]
    assert any("ç«è½¦ç¥¨" in c or "é«˜é“" in c for c in contents), "åº”è¯¥ä¿ç•™ç›¸å…³æ¶ˆæ¯"
    
    print("\nâœ… ç›¸å…³æ€§è¿‡æ»¤æµ‹è¯•é€šè¿‡!")


def test_density_calculation():
    """æµ‹è¯•ä¿¡æ¯å¯†åº¦è®¡ç®—"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•3: ä¿¡æ¯å¯†åº¦è®¡ç®—")
    print("=" * 50)
    
    optimizer = ContextOptimizer()
    
    # é«˜å¯†åº¦æ¶ˆæ¯(æ¯ä¸ªè¯éƒ½ä¸é‡å¤)
    high_density = [
        Message("user", "äººå·¥æ™ºèƒ½ æœºå™¨å­¦ä¹  æ·±åº¦å­¦ä¹ ", importance=5.0),
        Message("assistant", "è‡ªç„¶è¯­è¨€å¤„ç† è®¡ç®—æœºè§†è§‰ è¯­éŸ³è¯†åˆ«", importance=5.0)
    ]
    
    # ä½å¯†åº¦æ¶ˆæ¯(é‡å¤è¯å¤š)
    low_density = [
        Message("user", "ä½ å¥½ä½ å¥½ä½ å¥½ä½ å¥½ä½ å¥½", importance=5.0),
        Message("assistant", "å¥½çš„å¥½çš„å¥½çš„å¥½çš„å¥½çš„", importance=5.0)
    ]
    
    high_score = optimizer.calculate_density(high_density)
    low_score = optimizer.calculate_density(low_density)
    
    print(f"\né«˜å¯†åº¦æ¶ˆæ¯çš„å¯†åº¦: {high_score:.3f}")
    print(f"ä½å¯†åº¦æ¶ˆæ¯çš„å¯†åº¦: {low_score:.3f}")
    
    assert high_score > low_score, "é«˜å¯†åº¦æ¶ˆæ¯åº”è¯¥æœ‰æ›´é«˜çš„åˆ†æ•°"
    
    print("\nâœ… ä¿¡æ¯å¯†åº¦è®¡ç®—æµ‹è¯•é€šè¿‡!")


def test_summarize_optimization():
    """æµ‹è¯•æ€»ç»“å‹ç¼©(æ¨¡æ‹Ÿ)"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•4: æ€»ç»“å‹ç¼©(æ¨¡æ‹Ÿ)")
    print("=" * 50)
    
    # æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯
    class MockLLM:
        def chat(self, messages):
            return "ç”¨æˆ·å’¨è¯¢å¤©æ°”å’Œæ™¯ç‚¹æ¨è,åŠ©æ‰‹æä¾›äº†ç›¸å…³å»ºè®®ã€‚éšåç”¨æˆ·éœ€è¦é¢„è®¢åŒ—äº¬åˆ°ä¸Šæµ·çš„ç«è½¦ç¥¨ã€‚"
    
    optimizer = ContextOptimizer(llm_client=MockLLM())
    messages = create_test_messages()
    
    original_tokens = sum(estimate_tokens(msg.content) for msg in messages)
    print(f"\nåŸå§‹æ¶ˆæ¯: {len(messages)}æ¡, {original_tokens} tokens")
    
    # è®¾ç½®ä¸€ä¸ªè¾ƒå°çš„ç›®æ ‡å€¼ä»¥è§¦å‘å‹ç¼©
    optimized, result = optimizer.optimize(messages, target_tokens=80, strategy="summarize")
    
    print(result)
    
    print("ä¼˜åŒ–åçš„æ¶ˆæ¯:")
    for msg in optimized:
        tokens = estimate_tokens(msg.content)
        print(f"  [{msg.role}] ({tokens}t): {msg.content[:60]}...")
    
    # åº”è¯¥æœ‰å‹ç¼©æ•ˆæœæˆ–è‡³å°‘ä¿æŒåœ¨é™åˆ¶å†…
    assert result.optimized_tokens <= 80 or result.compression_ratio >= 0, "åº”è¯¥ä¼˜åŒ–æˆ–å‹ç¼©"
    print("\nâœ… æ€»ç»“å‹ç¼©æµ‹è¯•é€šè¿‡!")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\nğŸš€ å¼€å§‹æµ‹è¯•ä¸Šä¸‹æ–‡ä¼˜åŒ–å™¨...\n")
    
    test_truncate_optimization()
    test_relevance_filtering()
    test_density_calculation()
    test_summarize_optimization()
    
    print("\n" + "=" * 50)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    print("=" * 50)
    
    print("\nğŸ’¡ æç¤º:")
    print("  - æˆªæ–­ä¼˜åŒ–é€‚åˆè½»åº¦è¶…é™çš„æƒ…å†µ")
    print("  - æ€»ç»“å‹ç¼©é€‚åˆä¸¥é‡è¶…é™ä½†éœ€è¦ä¿ç•™å†å²ä¿¡æ¯")
    print("  - ç›¸å…³æ€§è¿‡æ»¤é€‚åˆä»å¤§é‡å†å²ä¸­æå–ç›¸å…³ä¿¡æ¯")
    print("  - æ··åˆç­–ç•¥åœ¨å®é™…åº”ç”¨ä¸­æ•ˆæœæœ€å¥½")


if __name__ == "__main__":
    run_all_tests()
